<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-overview/why_bean_machine/why_bean_machine">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.21">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Bean Machine RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Bean Machine Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-44373548-47","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">
<script src="https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js"></script>
<script src="https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js"></script><title data-rh="true">Why Bean Machine? | Bean Machine</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://beanmachine.org/docs/overview/why_bean_machine/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Why Bean Machine? | Bean Machine"><meta data-rh="true" name="description" content="Bean Machine is a probabilistic programming language that makes developing and deploying generative probabilistic models intuitive and efficient. This page describes the motivation for using Probabilistic Programming in general, and Bean Machine advantages specifically."><meta data-rh="true" property="og:description" content="Bean Machine is a probabilistic programming language that makes developing and deploying generative probabilistic models intuitive and efficient. This page describes the motivation for using Probabilistic Programming in general, and Bean Machine advantages specifically."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://beanmachine.org/docs/overview/why_bean_machine/"><link data-rh="true" rel="alternate" href="https://beanmachine.org/docs/overview/why_bean_machine/" hreflang="en"><link data-rh="true" rel="alternate" href="https://beanmachine.org/docs/overview/why_bean_machine/" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.d61208b3.css">
<link rel="preload" href="/assets/js/runtime~main.9559226e.js" as="script">
<link rel="preload" href="/assets/js/main.f35aac0c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script>
<div style="display: none; text-align: center; background-color: white; color: black;" id="internaldocs-banner"></div><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#20232a;color:#fff" role="banner"><div class="announcementBarContent_xLdY">Support Ukraine ðŸ‡ºðŸ‡¦ <a target="_blank" rel="noopener noreferrer" href="https://opensource.fb.com/support-ukraine"> Help Provide Humanitarian Aid to Ukraine</a>.</div></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/beanmachine.svg" alt="Bean Machine Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/beanmachine.svg" alt="Bean Machine Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bean Machine</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/overview/why_bean_machine/">Docs</a><a class="navbar__item navbar__link" href="/docs/overview/tutorials/Coin_flipping/CoinFlipping/">Tutorials</a><a href="/api/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebookresearch/beanmachine" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/overview/why_bean_machine/">Overview</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/overview/why_bean_machine/">Why Bean Machine?</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/quick_start/">Quick Start</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/modeling/">Modeling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/inference/">Inference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/analysis/">Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/installation/">Installation</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/world/">Framework</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/beanstalk/">Advanced</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/overview/tutorials/Coin_flipping/CoinFlipping/">Tutorials</a></div></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_GujU"><div class="docItemContainer_Adtb"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_aoJ5"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Why Bean Machine?</h1></header><p>Bean Machine is a probabilistic programming language that makes developing and deploying generative probabilistic models intuitive and efficient. This page describes the motivation for using <a href="#probabilistic-programming">Probabilistic Programming</a> in general, and <a href="#bean-machine-advantages">Bean Machine advantages</a> specifically.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="probabilistic-programming">Probabilistic Programming<a class="hash-link" href="#probabilistic-programming" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="generative-models">Generative Models<a class="hash-link" href="#generative-models" title="Direct link to heading">â€‹</a></h3><p>Bean Machine&#x27;s generative modeling is concerned not only with providing useful predictions (as traditional ML techniques do), but also with estimating the uncertainty inherent in the problem at hand in the form of probability distributions. Estimating uncertainty helps ensure that predictions are reliable and robust.</p><p>Generative modeling with Bean Machine offers many benefits:</p><ol><li><strong>Uncertainty estimation.</strong>  Predictions are quantified with reliable measures of uncertainty in the form of probability distributions. An analyst can understand not only the system&#x27;s prediction, but also the relative likelihood of other possibilities.</li><li><strong>Expressivity.</strong>  It&#x27;s extremely easy to encode a rich model directly in source code. This allows one to match the structure of the model to the structure of the problem.</li><li><strong>Interpretability.</strong>  Because the model matches the domain, one can query intermediate variables within the model as conceptually meaningful properties. This can be used to interpret <em>why</em> a particular prediction was made, and can aid the model development process.</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="generative-probabilistic-models">Generative Probabilistic Models<a class="hash-link" href="#generative-probabilistic-models" title="Direct link to heading">â€‹</a></h3><p>A generative probabilistic model consists of <em>random variables</em> and <em>conditional probability distributions</em> (CPDs) that encode knowledge about some domain. For example, consider a simplified model for the spread of infectious diseases, where we wish to express the idea that the average number of new cases on a given day is proportional to the current number of infections, with the proportionality constant being the daily reproduction rate of the disease. In order to express this mathematically, it is common practice to rely on <em>elementary probability distributions</em> (EPDs) with well known statistics, such as the <em>Poisson</em> distribution here:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">num_new ~ Poisson(reproduction_rate * num_init)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="bk-root thin-scrollbar" id="prior_poisson_intro" style="overflow:auto;width:100%"><div>loading...</div></div><p>Let&#x27;s fix for now the value of <code>num_init</code>, the initial number of infections, then the above statement gives the CPD of the random variable <code>num_new</code>, conditioned on the value of its <em>parent</em> random variable <code>reproduction_rate</code>. Since the parameter of the Poisson distribution is also its mean, this CPD is consistent with the knowledge that we were trying to express.</p><p>A well-formed generative model must specify the EPD or CPD of each random variable, and the <em>directed graph</em> induced by all the parent-child relationships among random variables must be <em>acyclic</em>. To complete our model, we must therefore also specify a distribution for the random variable <code>reproduction_rate</code>. In the case of new diseases, where we don&#x27;t know anything yet about the actual reproduction rate, this poses a seemingly intractable problem. In the <em>Bayesian approach</em> to this problem, we specify the probability distributions of random variables without parents as our <em><em>a priori</em></em> beliefs (i.e., before seeing any data) about them. So, in this example, if infectious disease experts believe that a new disease would have a daily reproduction rate which is strictly positive and could be expected to be drawn from a distribution with a mean of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span></span></span></span></span>, then we could express this belief with the help of another EPD, the <em>Exponential</em> distribution, as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">reproduction_rate ~ Exponential(1 / 0.1)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="bk-root thin-scrollbar" id="prior_exponential" style="overflow:auto;width:100%"><div>loading...</div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="inference">Inference<a class="hash-link" href="#inference" title="Direct link to heading">â€‹</a></h3><p>Given a generative model, the natural next step is to use it to perform inference. Inference is the process of combining a <em>model</em> with <em>data</em> to obtain <em>insights</em>, in the form of <em>a posteriori</em> beliefs over values of interest. Our documentation refers to the data as <em>observations</em>, to the values of interest as <em>queried random variables</em>, and to the insights as <em>posterior distributions</em>.</p><p>In our example above, let&#x27;s say we observe that <code>num_init = 1087980</code> and that <code>num_new = 238154</code>. Now, given this observation, we might want to query the posterior distribution for <code>reproduction_rate</code>. Mathematically speaking, we seek the following CPD:</p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">P</mi><mo stretchy="false">(</mo><mtext mathvariant="monospace">reproduction_rate</mtext><mtext>â€‰</mtext><mo>âˆ£</mo><mtext>â€‰</mtext><mtext mathvariant="monospace">num_init</mtext><mo>=</mo><mn>1087980</mn><mo separator="true">,</mo><mtext>â€…â€Š</mtext><mtext mathvariant="monospace">num_new</mtext><mo>=</mo><mn>238154</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{P}(\texttt{reproduction\_rate} \,\mid\, \texttt{num\_init}=1087980,\; \texttt{num\_new} = 238154)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathbb">P</span></span><span class="mopen">(</span><span class="mord text"><span class="mord texttt">reproduction_rate</span></span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">âˆ£</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:0.70625em;vertical-align:-0.09514em"></span><span class="mord text"><span class="mord texttt">num_init</span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">8</span><span class="mord">7</span><span class="mord">9</span><span class="mord">8</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord text"><span class="mord texttt">num_new</span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">2</span><span class="mord">3</span><span class="mord">8</span><span class="mord">1</span><span class="mord">5</span><span class="mord">4</span><span class="mclose">)</span></span></span></span></span></p><p>One way to understand the semantics of the inference task is to think of a generative probabilistic model as specifying a distribution over possible <em>worlds</em>. A world can be thought of as an assignment of specific admissible values to all random variables in the model. So, for example, some possible worlds in our case are:</p><ul><li><code>reproduction_rate = 0.01, num_new = 9000</code>,</li><li><code>reproduction_rate = 0.1, num_new = 90000</code>, or</li><li><code>reproduction_rate = 0.9, num_new = 800000</code>.</li></ul><p>Our generative model specifies a <em>joint</em> probability distribution over each of these worlds, based on the <em>prior</em> distribution we&#x27;ve chosen for <code>reproduction_rate</code> and the <em>likelihood</em> of <code>num_new</code> given some <code>reproduction_rate</code>. Now, the inference task is to restrict attention to only those worlds in which <code>num_new = 238154</code>. We&#x27;re interested in learning the resulting <em>posterior</em> distribution over <code>reproduction_rate</code> assignments within these worlds that are compatible with our observation.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="where-does-bean-machine-fit-in">Where Does Bean Machine Fit In?<a class="hash-link" href="#where-does-bean-machine-fit-in" title="Direct link to heading">â€‹</a></h3><p>In the rest of this Overview we&#x27;ll introduce you to Bean Machine&#x27;s syntax, and show you how it can be used to learn about problems like this one. Traditionally, lots of painstaking, hand-crafted work has gone into modeling generative scenarios. Bean Machine aims to handle all of the manual work involved in fitting data to your model, leaving you to focus on the exciting part: the problem itself! Keep on reading to find out how.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="target-audience">Target Audience<a class="hash-link" href="#target-audience" title="Direct link to heading">â€‹</a></h3><p>While we hope that the guides you&#x27;ll find here are relevant to anyone with an ML background, there are excellent resources available if this is your first exposure to Bayesian analysis! We highly recommend the excellent YouTube series <em><a href="https://www.youtube.com/playlist?list=PLDcUM9US4XdNM4Edgs7weiyIguLSToZRI" target="_blank" rel="noopener noreferrer">Statistical Rethinking</a></em>, which walks through Bayesian thinking and probabilistic modeling. For a more hands-on experience, you can check out the free, online tutorial <em><a href="https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/#contents" target="_blank" rel="noopener noreferrer">Bayesian Methods for Hackers</a></em>.</p><p>If you have previous knowledge of probabilistic programming, you may want to read below to learn more about specific details of the Bean Machine system. Otherwise, you can go directly to <a href="/docs/overview/quick_start/">Quick Start</a> for details on how Bean Machine is used!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bean-machine-advantages">Bean Machine Advantages<a class="hash-link" href="#bean-machine-advantages" title="Direct link to heading">â€‹</a></h2><p>Bean Machine builds on top of PyTorch with a declarative modeling syntax, being therefore simultaneously performant and intuitive for building probabilistic models. It balances automation with flexibility by implementing cutting-edge inference algorithms and allowing the user to select and program custom inferences for different problems and subproblems.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="site-based-inference">Site-Based Inference<a class="hash-link" href="#site-based-inference" title="Direct link to heading">â€‹</a></h3><p>Bean Machine uses a site-based inference engine. &quot;Sites&quot; are random variable families, and Bean Machine uses these families to enable a modular inference engine.</p><p>The simplest form of site-based inference is called &quot;single-site&quot; inference. In the single-site paradigm, models are built up from random variables that can be reasoned about individually. Bean Machine can exploit this modularity to update random variables one-at-a-time, reducing unnecessary computation and enabling posterior updates that might not be possible if processing the entire model in one go.</p><p>Bean Machine also supports &quot;multi-site&quot; inference. Multi-site inference reasons about multiple families of random variables jointly. This increases complexity during inference, but it allows the engine to exploit inter-site correlations when fitting the posterior distribution.</p><p>Altogether, site-based inference is a flexible pattern for trading off complexity and modularity, and enables the advanced techniques outlined below.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="declarative-modeling">Declarative Modeling<a class="hash-link" href="#declarative-modeling" title="Direct link to heading">â€‹</a></h3><p>Bean Machine provides a declarative syntax with first class support for random variables. This makes it intuitive for users to reason about their models in a program as they would on paper; a model is simply defined by a collection of random variables that interact with each other in a particular way.
In Bean Machine, random variables are implemented as decorated Python functions, which provide a unique pointer to that random variable. Using functions makes it simple to determine a random variable&#x27;s definition, since it is contained in a function that is usually only a few lines long. </p><p>This &#x27;localization&#x27; where a model is fully defined by a collection of random variables allows Bean Machine to easily track dependencies between them. Armed with the model structure, at inference time, Bean Machine can control which parts of the model get updated and explored.
As opposed to trace-based inference where a model execution is stored, operating directly with random variables as first class lazy objects and &quot;worlds&quot; to track their instantiations allows Bean Machine to reason about model specific structure such as control flow.
It also allows Bean machine to easily reorder model execution or perhaps update only a subgraph, saving significant amounts of compute in models with many latent variables.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="programmable-inference">Programmable Inference<a class="hash-link" href="#programmable-inference" title="Direct link to heading">â€‹</a></h3><p>Bean Machine allows the user to design and apply powerful inference methods. Because Bean Machine can propose updates for random variables or groups of random variables individually, the user is free to customize the <em>method</em> which it uses to propose those values. Different inference methods can be supplied for different families of random variables. For example, a particular model can leverage gradient information when proposing values for differentiable random variables, and at the same time might sample from discrete ones with a particle filter. This &quot;compositional inference&quot; pattern enables seamless interoperation among any MCMC-based inference strategies.</p><p>At the same time, the user has control over which variables should be updated (&quot;blocked&quot;) together versus independently, for instance for random variables that are tightly correlated. This &quot;multi-site inference&quot; may be able to further exploit multiple sites with inference-specific optimizations.
BeanMachine&#x27;s <code>CompositionalInference</code> API balances this flexibility with automation, automatically using proposers based on the support of the random variable, while allowing the user to specify how to build the best compositional MCMC proposer with virtually no additional effort.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="advanced-methods">Advanced Methods<a class="hash-link" href="#advanced-methods" title="Direct link to heading">â€‹</a></h3><p>Bean Machine supports a variety of classic inference methods such as ancestral sampling and the No-U-Turn sampler (NUTS). However, the framework also leverages single-site understanding of the model in order to provide efficient methods that take advantage of higher-order gradients and model structure.</p><p>Bean Machine includes the first implementation of Newtonian Monte Carlo (NMC) in a more general platform. NMC utilizes second-order gradient information to construct a multivariate Gaussian proposer that takes local curvature into account. As such, it can produce sample very efficiently with no warmup period when the posterior is roughly Gaussian. Bean Machine&#x27;s structural understanding of the model lets us keep computation relatively cheap by only modeling a subset of the space that is relevant to updating a particular random variable.</p><p>For certain domains, prepackaged inference methods may not be the best tool for the job. For example, if dealing with a problem specified in spherical coordinates, it may be useful to incorporate a notion of spherical locality into the inference proposal. Or, you may want to incorporate some notion of ordering when dealing with certain discrete random variables. Bean Machine exposes a flexible abstraction called <em>custom proposers</em> for just this problem. Custom proposers let the user design powerful new inference methods from the building blocks of existing ones, while easily plugging into Bean Machine&#x27;s multi-site paradigm.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="bean-machine-graph-compilation">Bean Machine Graph Compilation<a class="hash-link" href="#bean-machine-graph-compilation" title="Direct link to heading">â€‹</a></h3><p>PyTorch offers strong performance for models comprised of a small number of large tensors. However, many probabilistic models have a rich or sparse structure that is difficult to write in terms of just a handful of large tensor operations.
Also, certain inference algorithms such as NUTS have dynamic control flow, which incurs a significant amount of Python and PyTorch overhead during execution.</p><p>To address this, we are developing an experimental inference runtime called Bean Machine Graph (BMG) Inference. BMG Inference is a specialized combination of a compiler and a fast, independent C++ runtime that is optimized to run inference even for un-tensorized models. By design, BMG Inference has the same interface as other Bean Machine inference methods, relying on a custom behind-the-scenes compiler to interpret your model and translate it to a faster implementation with no Python dependencies.</p><p>BMG Inference routinely achieves 1 to 2 orders-of-magnitude speedup for untensorized models. However, please note that this infrastructure is under development, and the supported feature set may be limited.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebookresearch/beanmachine/edit/main/website/../docs/overview/why_bean_machine/why_bean_machine.mdx" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_eYIM" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vbeJ"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/docs/overview/quick_start/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Quick Start</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#probabilistic-programming" class="table-of-contents__link toc-highlight">Probabilistic Programming</a><ul><li><a href="#generative-models" class="table-of-contents__link toc-highlight">Generative Models</a></li><li><a href="#generative-probabilistic-models" class="table-of-contents__link toc-highlight">Generative Probabilistic Models</a></li><li><a href="#inference" class="table-of-contents__link toc-highlight">Inference</a></li><li><a href="#where-does-bean-machine-fit-in" class="table-of-contents__link toc-highlight">Where Does Bean Machine Fit In?</a></li><li><a href="#target-audience" class="table-of-contents__link toc-highlight">Target Audience</a></li></ul></li><li><a href="#bean-machine-advantages" class="table-of-contents__link toc-highlight">Bean Machine Advantages</a><ul><li><a href="#site-based-inference" class="table-of-contents__link toc-highlight">Site-Based Inference</a></li><li><a href="#declarative-modeling" class="table-of-contents__link toc-highlight">Declarative Modeling</a></li><li><a href="#programmable-inference" class="table-of-contents__link toc-highlight">Programmable Inference</a></li><li><a href="#advanced-methods" class="table-of-contents__link toc-highlight">Advanced Methods</a></li><li><a href="#bean-machine-graph-compilation" class="table-of-contents__link toc-highlight">Bean Machine Graph Compilation</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Legal</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener" class="footer__link-item">Terms<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_lCJq"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a href="https://opensource.facebook.com" target="_blank" rel="noopener noreferrer" class="footerLogoLink_BH7S"><img src="/img/beanmachine.svg" alt="Bean Machine Logo" class="themedImage_ToTc themedImage--light_HNdA footer__logo"><img src="/img/beanmachine.svg" alt="Bean Machine Logo" class="themedImage_ToTc themedImage--dark_i4oU footer__logo"></a></div><div class="footer__copyright">Copyright &#169; 2022 Meta Platforms, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.9559226e.js"></script>
<script src="/assets/js/main.f35aac0c.js"></script>
</body>
</html>