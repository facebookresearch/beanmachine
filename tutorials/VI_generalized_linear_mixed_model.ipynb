{
  "metadata": {
    "dataExplorerConfig": {},
    "interpreter": {
      "hash": "2d13082b4bd245bb7b08aea3b25cb3b8185404358d859b3f501f7ea456008ea8"
    },
    "kernelspec": {
      "display_name": "beanmachine",
      "language": "python",
      "name": "bento_kernel_beanmachine",
      "metadata": {
        "kernel_name": "bento_kernel_beanmachine",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "cinder_runtime": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "last_server_session_id": "f9e5d038-b5f8-44a4-8a08-e347319bc75a",
    "last_kernel_id": "373188a6-cca3-465b-b962-138be8cbb74f",
    "last_base_url": "https://devvm7339.prn0.facebook.com:8090/",
    "last_msg_id": "bbed486c-eba249e56813c1afe37839da_23",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "a89f4cdd-d15a-45b4-98c2-3e181335e4b6"
      },
      "source": [
        "Adapted from:\n",
        "* https://www.tensorflow.org/probability/examples/Linear_Mixed_Effects_Model_Variational_Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d1b673af-67d4-40fc-9384-71ec3c45f9c0"
      },
      "source": [
        "from beanmachine.tutorials.utils.radon import load_data\n",
        "\n",
        "df = load_data()\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "9482d62c-64c3-4e76-81d7-e492926d4b10"
      },
      "source": [
        "There are two `floor`s with lots of data and many counties with little data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "dd213a1b-3fac-4558-a19f-3761487ac4b3"
      },
      "source": [
        "from matplotlib import pyplot as plt; plt.style.use('fivethirtyeight')\n",
        "import seaborn as sns; sns.set_context('notebook')\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 5]}, figsize=(12, 3))\n",
        "df['floor'].value_counts().plot(kind='bar', ax=ax[0])\n",
        "df['county'].value_counts().plot(kind='bar', ax=ax[1])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "29f20e29-148b-45c6-be68-a51f5d03f016"
      },
      "source": [
        "Since many counties have little data, to avoid overfitting county effects we will model it as a random effect within a GLMM:\n",
        "\n",
        "$$\\log \\text{radon}_j \\sim c + \\text{floor\\_effect}_j + \\mathcal{N}(\\text{county\\_effect}_j, \\text{county\\_scale})$$\n",
        "\n",
        "Note that the scale here is global across all counties and the random effect is normal; the [hierarchical linear mixed effects models](https://en.wikipedia.org/wiki/Hierarchical_generalized_linear_model) we will look at later will generalize this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6d1557c4-50d2-4d96-b4e7-b3cf5a10f70c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4920ecf9-df2f-4ca0-8d25-4a86999d7890"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "features = df[['county_index', 'floor']].astype(int)\n",
        "labels = df[['log_activity']].astype(np.float32).values.flatten()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "deba6214-9a8b-47c1-bba3-8e4b29891e37"
      },
      "source": [
        "import beanmachine.ppl as bm\n",
        "import torch\n",
        "import torch.distributions as dist\n",
        "\n",
        "floor = torch.tensor(features.floor.values)\n",
        "county_index = torch.tensor(features.county_index.values)\n",
        "\n",
        "@bm.random_variable\n",
        "def county_scale():\n",
        "    return dist.HalfNormal(scale=1.)\n",
        "\n",
        "@bm.random_variable\n",
        "def intercept():\n",
        "    return dist.Normal(loc=0., scale=1.)\n",
        "\n",
        "@bm.random_variable\n",
        "def floor_weight():\n",
        "    return dist.Normal(loc=0., scale=1.)\n",
        "\n",
        "@bm.random_variable\n",
        "def county_prior():\n",
        "    return dist.Independent(dist.Normal(\n",
        "        loc=torch.zeros(county_index.unique().numel()),\n",
        "        scale=county_scale(),\n",
        "    ), 1)\n",
        "\n",
        "\n",
        "@bm.random_variable\n",
        "def linear_response():\n",
        "    fixed_effect = intercept() + floor_weight() * floor\n",
        "    random_effect = torch.gather(county_prior(), 0, county_index)\n",
        "    return dist.Independent(dist.Normal(\n",
        "        loc=fixed_effect + random_effect,\n",
        "        scale=1.,\n",
        "    ), 1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f9d875aa-a02e-4756-9a43-2e11c0ebc0b8"
      },
      "source": [
        "from torch.distributions import constraints\n",
        "from torch.distributions.transforms import Transform\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SoftplusTransform(Transform):\n",
        "    r\"\"\"\n",
        "    Transform via the mapping :math:`y = \\log(1 + \\exp(x))`\n",
        "\n",
        "    Source: https://discuss.pytorch.org/t/branching-for-numerical-stability/15763/4\n",
        "    \"\"\"\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.positive\n",
        "    bijective = True\n",
        "    sign = +1\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.threshold = 20\n",
        "\n",
        "    def _call(self, x):\n",
        "        return F.softplus(x)\n",
        "\n",
        "    def _inverse(self, y):\n",
        "        return torch.where(y>self.threshold, y, y.expm1().log())\n",
        "\n",
        "    def log_abs_det_jacobian(self, x, y):\n",
        "        return F.logsigmoid(x)\n",
        "\n",
        "@bm.param\n",
        "def phi_loc():\n",
        "    return torch.rand(3) * 4 - 2\n",
        "\n",
        "@bm.param\n",
        "def phi_scale():\n",
        "    return torch.rand(3) + 0.01\n",
        "\n",
        "@bm.random_variable\n",
        "def q_county_scale():\n",
        "    return dist.TransformedDistribution(dist.Normal(phi_loc()[0], F.softplus(phi_scale()[0])), [SoftplusTransform()])\n",
        "\n",
        "@bm.random_variable\n",
        "def q_intercept():\n",
        "    return dist.Normal(phi_loc()[1], F.softplus(phi_scale()[1]))\n",
        "\n",
        "@bm.random_variable\n",
        "def q_floor_weight():\n",
        "    return dist.Normal(phi_loc()[2], F.softplus(phi_scale()[2]))\n",
        "\n",
        "\n",
        "# indexing was too hard, so I made another param\n",
        "# NOTE: can we automate this or make it easier? as a beanstalk fixer?\n",
        "@bm.param\n",
        "def phi_county_prior_loc():\n",
        "    return torch.rand(county_index.unique().numel()) * 4 - 2\n",
        "\n",
        "@bm.param\n",
        "def phi_county_prior_scale():\n",
        "    return torch.rand(county_index.unique().numel()) + 0.01\n",
        "\n",
        "@bm.random_variable\n",
        "def q_county_prior():\n",
        "    return dist.Independent(dist.Normal(\n",
        "        loc=phi_county_prior_loc(),\n",
        "        scale=F.softplus(phi_county_prior_scale()),\n",
        "    ), 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "31410e85-6bc5-4df7-975b-29aacda56d43"
      },
      "source": [
        "%aimport"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4029a6de-0495-454c-8f2e-eb204b6a60d9"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "vi = bm.VariationalInfer(\n",
        "    queries_to_guides={\n",
        "        county_prior(): q_county_prior(),\n",
        "        floor_weight(): q_floor_weight(),\n",
        "        intercept(): q_intercept(),\n",
        "        county_scale(): q_county_scale(),\n",
        "    },\n",
        "    observations={\n",
        "        linear_response(): torch.tensor(labels),\n",
        "    },\n",
        "    optimizer=lambda params: torch.optim.Adam(params, lr=1e-2),\n",
        ")\n",
        "\n",
        "num_steps = 1000\n",
        "losses = torch.empty(num_steps)\n",
        "for i in tqdm(range(num_steps)):\n",
        "    loss, _ = vi.step()\n",
        "    losses[i] = loss\n",
        "\n",
        "world = vi._world\n",
        "for guide in vi.queries_to_guides.values():\n",
        "    world.initialize_value(guide)\n",
        ""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "1eb42ff3-7e1c-4fbb-b2e9-40e78fae5b63"
      },
      "source": [
        "Our variational approximations for the linear fixed effects model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b0e15f7f-c83d-4c50-8ab1-ded79448d961"
      },
      "source": [
        "world.get_variable(q_intercept()).distribution"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bc3d84ac-867b-4223-a82f-8a11d38189eb"
      },
      "source": [
        "world.get_variable(q_floor_weight()).distribution"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "5c78ca92-8046-436c-8026-328b34b88428"
      },
      "source": [
        "We have to Monte-Carlo approximate `q_scale_prior` since closed form means are not always available after pushforward (ie `TransformedDistribution.mean` is unimplemented)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1d1bf49f-6569-4c4f-9f18-561df3fb8824"
      },
      "source": [
        "scale_prior_sample = world.get_variable(q_county_scale()).distribution.sample((100000,))\n",
        "print(\n",
        "    scale_prior_sample.mean(),\n",
        "    scale_prior_sample.var(),\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b8c32e98-0b61-4793-8057-a3bc35765450"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "ax = pd.DataFrame({\n",
        "    \"losses\": losses.detach().numpy()\n",
        "}).plot(kind='line')\n",
        "ax.set_ylabel(\"ELBO\")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "550be274-8811-429e-b658-715516bd20ea"
      },
      "source": [
        "county_counts = (df.groupby(by=['county', 'county_index'], observed=True)\n",
        "                   .agg('size')\n",
        "                   .sort_values(ascending=False)\n",
        "                   .reset_index(name='count'))\n",
        "\n",
        "means = world.get_variable(q_county_prior()).distribution.base_dist.mean.detach().numpy()\n",
        "stds = world.get_variable(q_county_prior()).distribution.base_dist.stddev.detach().numpy()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "for idx, row in county_counts.iterrows():\n",
        "  mid = means[row.county_index]\n",
        "  std = stds[row.county_index]\n",
        "  ax.vlines(idx, mid - std, mid + std, linewidth=3)\n",
        "  ax.plot(idx, means[row.county_index], 'ko', mfc='w', mew=2, ms=7)\n",
        "\n",
        "ax.set(\n",
        "    xticks=np.arange(len(county_counts)),\n",
        "    xlim=(-1, len(county_counts)),\n",
        "    ylabel=\"County effect\",\n",
        "    title=r\"Estimates of county effects on log radon levels. (mean $\\pm$ 1 std. dev.)\",\n",
        ")\n",
        "ax.set_xticklabels(county_counts.county, rotation=90);"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "372e28b6-1f64-4bd2-8a3a-032e843ba12b"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "ax.plot(np.log1p(county_counts['count']), stds[county_counts.county_index], 'o')\n",
        "ax.set(\n",
        "    ylabel='Posterior std. deviation',\n",
        "    xlabel='County log-count',\n",
        "    title='Having more observations generally\\nlowers estimation uncertainty'\n",
        ");"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "0ddba2b3-1104-4bc4-ae60-8dca1079cf98"
      },
      "source": [
        "In addition, we can also perform MAP instead of variational approximation for (parts of) the model. For example, here we consider obtaining MAP estimates for the fixed effects part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c0379211-3c91-468b-90b3-c254a8b7813b"
      },
      "source": [
        "import beanmachine.ppl as bm\n",
        "import torch\n",
        "import torch.distributions as dist\n",
        "from tqdm.auto import tqdm\n",
        "from beanmachine.ppl.distributions import Delta, Flat\n",
        "\n",
        "floor = torch.tensor(features.floor.values)\n",
        "county_index = torch.tensor(features.county_index.values)\n",
        "\n",
        "@bm.random_variable\n",
        "def county_scale():\n",
        "    return dist.HalfNormal(scale=1.)\n",
        "\n",
        "@bm.random_variable\n",
        "def intercept():\n",
        "    return Flat()\n",
        "\n",
        "@bm.random_variable\n",
        "def floor_weight():\n",
        "    return Flat()\n",
        "\n",
        "@bm.random_variable\n",
        "def county_prior():\n",
        "    return dist.Independent(dist.Normal(\n",
        "        loc=torch.zeros(county_index.unique().numel()),\n",
        "        scale=county_scale(),\n",
        "    ), 1)\n",
        "\n",
        "\n",
        "@bm.random_variable\n",
        "def linear_response():\n",
        "    fixed_effect = intercept() + floor_weight() * floor\n",
        "    random_effect = torch.gather(county_prior(), 0, county_index)\n",
        "    return dist.Independent(dist.Normal(\n",
        "        loc=fixed_effect + random_effect,\n",
        "        scale=1.,\n",
        "    ), 1)\n",
        "\n",
        "@bm.param\n",
        "def phi_loc():\n",
        "    return torch.rand(3) * 4 - 2\n",
        "\n",
        "@bm.param\n",
        "def phi_scale():\n",
        "    return torch.rand(1) * 4 - 2\n",
        "\n",
        "@bm.random_variable\n",
        "def q_county_scale():\n",
        "    return dist.TransformedDistribution(dist.Normal(phi_loc()[0], F.softplus(phi_scale()[0])), [SoftplusTransform()])\n",
        "\n",
        "@bm.random_variable\n",
        "def q_intercept():\n",
        "    return Delta(phi_loc()[1])\n",
        "\n",
        "@bm.random_variable\n",
        "def q_floor_weight():\n",
        "    return Delta(phi_loc()[2])\n",
        "\n",
        "vi = bm.VariationalInfer(\n",
        "    queries_to_guides={\n",
        "        county_prior(): q_county_prior(),\n",
        "        floor_weight(): q_floor_weight(),\n",
        "        intercept(): q_intercept(),\n",
        "        county_scale(): q_county_scale(),\n",
        "    },\n",
        "    observations={\n",
        "        linear_response(): torch.tensor(labels),\n",
        "    },\n",
        "    optimizer=lambda params: torch.optim.Adam(params, lr=1e-2),\n",
        ")\n",
        "\n",
        "num_steps = 1000\n",
        "losses = torch.empty(num_steps)\n",
        "for i in tqdm(range(num_steps)):\n",
        "    loss, _ = vi.step(num_samples=2)\n",
        "    losses[i] = loss\n",
        "\n",
        "world = vi._world\n",
        "for guide in vi.queries_to_guides.values():\n",
        "    world.initialize_value(guide)\n",
        ""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3b32d475-9167-49aa-8dc2-f5e96d75f7a6"
      },
      "source": [
        "world.get_variable(q_floor_weight())"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "43a46f20-06dc-4f48-9163-9fedd540c09c"
      },
      "source": [
        "world.get_variable(q_intercept())"
      ],
      "execution_count": 65,
      "outputs": []
    }
  ]
}
