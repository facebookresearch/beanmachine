{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181fb009-f0cb-4f5a-a4f7-4800cf7bf358",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial: **Hierarchical modeling with repeated binary trial data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132af4f2-ee04-4d60-9c99-07ec70728933",
   "metadata": {},
   "source": [
    "In this tutorial we will demonstrate the application of *hierarchical models*\n",
    "with data from the 1970 season of [Major League Baseball (MLB)](#references)\n",
    "found in the paper by [Efron and Morris 1975](#references)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a265f5-3450-41c2-b36f-ef58d88b9a5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918ee9c-5c76-4147-be26-450acabc9fd7",
   "metadata": {},
   "source": [
    "On completion of this tutorial, you should be able:\n",
    "\n",
    "* to prepare data for running a hierarchical model with Bean Machine;\n",
    "* to execute a hierarchical model with Bean Machine;\n",
    "* to explain what different pooling techniques tell us about the data;\n",
    "* to run diagnostics to understand what Bean Machine is doing; and\n",
    "* to generalize the techniques demonstrated to build a hierarchical model based\n",
    "  on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b4188-657b-4f0b-9001-3c40aa261826",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d14907-fd8c-42e0-a3f2-c8c093db331c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Data are from [Efron and Morris 1975](#references), which are taken from the\n",
    "1970 Major League Baseball season for both the American and National leagues,\n",
    "[Wikipedia (Major League Baseball)](#references). These data are an example of\n",
    "_repeated binary trials_ in that a player has multiple opportunities (trials)\n",
    "for being at-bat and they can either land a hit or miss the ball (binary\n",
    "outcome). Many useful scenarios can be modeled as having repeated binary\n",
    "trials. For example; browser click data, watching a video to completion, voting\n",
    "for or against propositions in a session of congress/parliament, and even rat\n",
    "tumor development, see [Tarone](#references).\n",
    "\n",
    "**Our task is to use the given baseball data and create a _hierarchical_ model\n",
    "that estimates the chances each player has to land a hit when they are at-bat.**\n",
    "The term `hierarchical` invokes concepts of there being a hierarchy within the\n",
    "data, _e.g._ country > state > city, however, our baseball data does not contain\n",
    "an explicit hierarchy. Nonetheless we can use a hierarchical model to describe\n",
    "the data. We create a \"hierarchy\" by stating that all the data are from MLB\n",
    "players. Each individual player is different, however, all players are from the\n",
    "MLB. So the population is sampled from the MLB, and our individuals are all\n",
    "different players. Thus our \"hierarchy\" is MLB-population > MLB-player. We can\n",
    "do this even though we do not have any explicit data on the MLB population.\n",
    "Later on we will create a model where we estimate population parameters and we\n",
    "will use that knowledge to update the chances a player has to hit a ball when\n",
    "at-bat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28952391-cb63-4ff1-a775-58ad851c4fe3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06859dd6-f847-4cb6-842c-a78b803e87fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "We wil be using the following packages within this tutorial.\n",
    "\n",
    "* [`beanmachine`](#references) the Bean Machine library;\n",
    "* [`arviz`](https://arviz-devs.github.io/arviz/);\n",
    "  [`bokeh`](https://docs.bokeh.org/en/latest/docs/) for interactive\n",
    "  visualizations;\n",
    "* [`numpy`](https://numpy.org/) and [`pandas`](https://pandas.pydata.org/) for\n",
    "  data manipulation;\n",
    "* [`torch`](https://pytorch.org/) for fundamental PyTorch classes; and\n",
    "* [`statsmodels`](https://www.statsmodels.org/) for simple statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282d60d-f182-4ffc-952f-5e4fd4ae454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import arviz as az\n",
    "import beanmachine.ppl as bm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "from beanmachine.ppl.model import RVIdentifier\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import Arrow, Band, ColumnDataSource, HoverTool, VeeHead, Whisker\n",
    "from bokeh.plotting import figure, gridplot, show\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd7d9d1-b51a-4456-bd53-d2de15704733",
   "metadata": {},
   "source": [
    "The next cell includes convenient configuration settings to improve the notebook\n",
    "presentation as well as setting a manual seed for `torch` for reproducibilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a5f27-1c59-405e-ada7-93c46c192f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting settings\n",
    "az.style.use('arviz-darkgrid')\n",
    "az.rcParams['plot.backend'] = 'bokeh'\n",
    "az.rcParams['plot.bokeh.tools'] = ','.join(\n",
    "    [\n",
    "        'reset',\n",
    "        'pan',\n",
    "        'box_zoom',\n",
    "        'wheel_zoom',\n",
    "        'lasso_select',\n",
    "        'undo',\n",
    "        'save',\n",
    "        'hover',\n",
    "        'crosshair',\n",
    "    ]\n",
    ")\n",
    "az.rcParams['plot.bokeh.figure.dpi'] = 60\n",
    "az.rcParams['stats.hdi_prob'] = 0.89\n",
    "\n",
    "# Manual seed for torch\n",
    "torch.manual_seed(1199)\n",
    "\n",
    "# Other settings for the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9e392-3caf-4d54-bd43-87ed9e19ff32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b2c24-f4c0-4054-b653-fbee63721136",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will explore the data first so we can create a _data story_. We will use the\n",
    "_data story_ to inform decisions that need to be made about priors and sampling\n",
    "distributions when we begin to make models. The story will be used to create\n",
    "logical procedures for processing information, see [McElreath](#references) for\n",
    "further discussion about data stories.\n",
    "\n",
    "The data columns are explained as follows.\n",
    "\n",
    "| Column name      | Description                                     |\n",
    "|------------------|-------------------------------------------------|\n",
    "| FirstName        | Player's first name                             |\n",
    "| LastName         | Player's last name                              |\n",
    "| At-Bats          | 45 for each player                              |\n",
    "| Hits             | Hits in first 45 at-bats                        |\n",
    "| BattingAverage   | Batting average after first 45 at-bats          |\n",
    "| RemainingAt-Bats | Batting average for the remainder of the season |\n",
    "| SeasonAt-Bats    | Number of at-bats for entire season             |\n",
    "| Season Hits      | Number of hits for entire season                |\n",
    "| SeasonAverage    | Batting average for entrie season               |\n",
    "\n",
    "The selected players include _Roberto Clemente_ explicitly because he was\n",
    "presumed to be an outlier. See [Efron and Morris, 1977](#references) for further\n",
    "discussion.\n",
    "\n",
    "We now read the data in as a Pandas dataframe. The data are replicated below\n",
    "using a `StringIO` object rather than reading from a `CSV` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fa5dd-ec8c-4f1f-ad54-53c945dc4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data are from Efron and Morris (1975).\n",
    "data_string = \"\"\"FirstName,LastName,At-Bats,Hits,BattingAverage,RemainingAt-Bats,RemainingAverage,SeasonAt-Bats,Season Hits,SeasonAverage\n",
    "Roberto,Clemente,45,18,0.4,367,0.346,412,145,0.352\n",
    "Frank,Robinson,45,17,0.378,426,0.2981,471,144,0.306\n",
    "Frank,Howard,45,16,0.356,521,0.2764,566,160,0.283\n",
    "Jay,Johnstone,45,15,0.333,275,0.2218,320,76,0.238\n",
    "Ken,Berry,45,14,0.311,418,0.2727,463,128,0.276\n",
    "Jim,Spencer,45,14,0.311,466,0.2704,511,140,0.274\n",
    "Don,Kessinger,45,13,0.289,586,0.2645,631,168,0.266\n",
    "Luis,Alvarado,45,12,0.267,138,0.2101,183,41,0.224\n",
    "Ron,Santo,45,11,0.244,510,0.2686,555,148,0.267\n",
    "Ron,Swaboda,45,11,0.244,200,0.23,245,57,0.233\n",
    "Rico,Petrocelli,45,10,0.222,538,0.2639,583,152,0.261\n",
    "Ellie,Rodriguez,45,10,0.222,186,0.2258,231,52,0.225\n",
    "George,Scott,45,10,0.222,435,0.3034,480,142,0.296\n",
    "Del,Unser,45,10,0.222,277,0.2635,322,83,0.258\n",
    "Billy,Williams,45,10,0.222,591,0.3299,636,205,0.251\n",
    "Bert,Campaneris,45,9,0.2,558,0.2849,603,168,0.279\n",
    "Thurman,Munson,45,8,0.178,408,0.3162,453,137,0.302\n",
    "Max,Alvis,45,7,0.156,70,0.2,115,21,0.183\"\"\"\n",
    "with StringIO(data_string) as f:\n",
    "    df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50247bdd-0865-456c-8f9c-c39c3ae0816f",
   "metadata": {},
   "source": [
    "The next cell contains standard `pandas` transformations to make the data\n",
    "clearer for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34e694-b216-467d-b00f-1fbeb309821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in order to make the data clearer.\n",
    "renames = {\n",
    "    'Hits': 'Current hits',\n",
    "    'At-Bats': 'Current at-bats',\n",
    "    'Season Hits': 'Season hits',\n",
    "    'SeasonAt-Bats': 'Season at-bats',\n",
    "}\n",
    "df = df.rename(columns=renames)\n",
    "\n",
    "# Concatenate the first and last names together.\n",
    "df['Name'] = df['FirstName'].str.cat(df['LastName'], sep=' ')\n",
    "\n",
    "# Keep only those columns we will use in the analysis.\n",
    "df = df[\n",
    "    [\n",
    "        'Name',\n",
    "        'Current hits',\n",
    "        'Current at-bats',\n",
    "        'Season hits',\n",
    "        'Season at-bats',\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Show the resultant dataframe.\n",
    "df.set_index('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef3d685-ddf3-450a-b6a7-a0b12fa511f9",
   "metadata": {},
   "source": [
    "The above dataframe shows us that each player had a different number of\n",
    "opportunities to be at-bat over the course of the season; the `Season at-bats`\n",
    "column. We also see a defined slice in time where all the players have had the\n",
    "same number of opportunities to be at-bat, the `Current at-bats` column. The\n",
    "`Current at-bats` column is the number of trials each player has had to be\n",
    "at-bat, all of which are 45. The number of successful hits a player has made\n",
    "within the first 45 trials is given in the `Current hits` column. From the\n",
    "dataframe, we can see that we have indeed have _repeated binary trials_ data.\n",
    "\n",
    "The data are telling us that each player is unique, but also that they are\n",
    "similar. The players are similar because they are all highly trained in their\n",
    "sport, and have a much better chance of hitting a ball when at-bat then an\n",
    "average person not in the MLB. The data also tell us that we have captured a\n",
    "slice in time where each player has been given the same number of opportunities\n",
    "to be at-bat, and all of them had different amounts of success at landing a\n",
    "hit.\n",
    "\n",
    "This is now our **data story**: MLB players are unique because they have\n",
    "different abilities associated with hitting a ball, but they are all similar in\n",
    "that they are all highly skilled athletes. Our **problem** is to now: estimate\n",
    "player's abilities and their chances of hitting a ball when at-bat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbbb26b-1e17-48c8-858c-5b93642fe4d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891cbf9-acb8-4ab2-9f5f-f811753a93c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "We will create three separate models using the above data as we explore how to\n",
    "create a hierarchical model using Bean Machine|. The models we will be creating\n",
    "are:\n",
    "\n",
    "* [complete-pooling](#complete-pooling);\n",
    "* [no-pooling](#no-pooling);\n",
    "* [partial-pooling](#parital-pooling).\n",
    "\n",
    "Each model will estimate a baseball player's chance of landing a hit when they\n",
    "are at-bat. We can assume that every time a player is at-bat is a new\n",
    "independent Bernoulli trial (see [Wikipedia (Bernoulli trial)](#references)) so\n",
    "we can model the chance a player has when at-bat as a Binomial distribution,\n",
    "see [Wikipedia (Binomial)](#references).\n",
    "\n",
    "$$\n",
    "p(y_n | \\phi) = \\text{Binomial}(y_n | K_n, \\phi)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\phi$ is our prior;\n",
    "* $y_n$ are the number of times a player makes a hit (number of successes);\n",
    "* $K_n$ is the number of times that player has been at-bat (number of trials)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b271e624-3758-4ec3-a699-f7294789edba",
   "metadata": {
    "tags": []
   },
   "source": [
    "**`NOTE`** We can implement all of these models in Bean Machine by defining\n",
    "random variable objects with the `@bm.random_variable` decorator. These\n",
    "functions behave differently than ordinary Python functions. In each of the\n",
    "models below we will see how to use the `@bm.random_variable` decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a64ef-a216-473e-add8-fdd7b713d5ff",
   "metadata": {},
   "source": [
    "<div style= \"background: #daeaf3; border-left: 3px solid #2980b9; display: block; margin: 16px 0; padding: 12px;\">\n",
    "  Semantics for <code>@bm.random_variable</code> functions:\n",
    "  <ul>\n",
    "    <li>They must return PyTorch <code>Distribution</code> objects.</li>\n",
    "    <li>\n",
    "      Though they return distributions, callees actually receive a <i>sample</i>\n",
    "      from the distribution. The machinery for obtaining samples from\n",
    "      distributions is handled internally by Bean Machine.\n",
    "    </li>\n",
    "    <li>\n",
    "      Inference runs the model through many iterations. During a particular\n",
    "      inference iteration, a distinct random variable will correspond to\n",
    "        exactly one sampled value: <b>calls to the same random variable\n",
    "          function with the same arguments will receive the same sampled value\n",
    "          within one inference iteration</b>. This makes it easy for multiple\n",
    "        components of your model to refer to the same logical random variable.\n",
    "    </li>\n",
    "    <li>\n",
    "      Consequently, to define distinct random variables that correspond to\n",
    "      different sampled values during a particular inference iteration, an\n",
    "      effective practice is to add a dummy \"indexing\" parameter to the\n",
    "      function. Distinct random variables can be referred to with different\n",
    "      values for this index.\n",
    "    </li>\n",
    "    <li>\n",
    "      Please see the documentation for more information about this decorator.\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038871e-078e-4aee-a3ee-fbed5f416a07",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"complete-pooling\"></a>\n",
    "### Complete-pooling model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa815d9-d70e-40d3-94da-b04ac8dfddf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Complete pooling assumes every item being modeled is identical. This means for\n",
    "our baseball data that we will be modeling each player as if their chance of\n",
    "getting a hit when at-bat is the same for everyone. As we will see later on,\n",
    "this is going to underestimate top batter's abilities and overestimate poor\n",
    "batter's abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d518f-586d-4f3e-807d-ab832f67cd6e",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img src=\"img/complete-pooling.svg\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94915bd4-ed38-43b7-8521-3322e201d1bd",
   "metadata": {},
   "source": [
    "The image above is a graphical representation of what complete pooling does: it\n",
    "assumes that everyone is sampled from the same population distribution $\\phi$.\n",
    "This model assumes that all the players are the _same_, which is an extreme\n",
    "statement compared to our data story that said all players were _similar_. This\n",
    "is something we will fix later on.\n",
    "\n",
    "If we assume no prior knowledge about the players then our prior ($\\phi$)\n",
    "is a uniform distribution from $[0, 1]$. Bean Machine works well with `Uniform`\n",
    "priors, but we will choose to use a $\\text{Beta(1, 1)}$ distribution as our\n",
    "prior because it is a conjugate prior to a Binomial distribution. Our\n",
    "`complete-pooling` model can be written as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\phi & \\sim\\text{Beta}(1, 1)\\\\\n",
    "  y    & \\sim\\text{Binomial}(K, \\phi).\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd515632-dfdf-40da-be00-30d23491e18a",
   "metadata": {},
   "source": [
    "#### Beta priors _vs_ Uniform priors\n",
    "Below we show the similarity between a uniform distribution and a Beta\n",
    "distribution.\n",
    "\n",
    "**`Note`** that we have chosen to show a sampling from both distributions, and\n",
    "then to calculate the probability distribution function using `statsmodels` in\n",
    "order to compare the two. Analytic plots for a Beta and Uniform distribution\n",
    "would show plots with exactly straight lines on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51d27c-f450-4478-9c80-280e51fb8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = dist.Beta(1., 1.)\n",
    "uniform = dist.Uniform(low=0., high=1.)\n",
    "\n",
    "N = int(1e6)\n",
    "beta_samples = beta.sample((N,))\n",
    "uniform_samples = uniform.sample((N,))\n",
    "\n",
    "beta_kde = sm.nonparametric.KDEUnivariate(beta_samples)\n",
    "beta_kde.fit()\n",
    "uniform_kde = sm.nonparametric.KDEUnivariate(uniform_samples)\n",
    "uniform_kde.fit()\n",
    "\n",
    "plot = figure(\n",
    "    plot_width=400,\n",
    "    plot_height=400,\n",
    "    title='Beta(1, 1) vs Uniform',\n",
    "    x_axis_label='Support',\n",
    "    x_range=[0, 1],\n",
    "    y_range=[0.8, 1.2],\n",
    ")\n",
    "\n",
    "beta_source = ColumnDataSource(\n",
    "    {\n",
    "        'x': beta_kde.support,\n",
    "        'y': beta_kde.density / beta_kde.density.max(),\n",
    "    }\n",
    ")\n",
    "beta_glyph = plot.line(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    source=beta_source,\n",
    "    line_color='steelblue',\n",
    "    line_alpha=0.7,\n",
    "    line_width=2,\n",
    "    legend_label='Beta(1, 1)',\n",
    ")\n",
    "\n",
    "uniform_source = ColumnDataSource(\n",
    "    {\n",
    "        'x': uniform_kde.support,\n",
    "        'y': uniform_kde.density / uniform_kde.density.max(),\n",
    "    }\n",
    ")\n",
    "uniform_glyph = plot.line(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    source=uniform_source,\n",
    "    line_color='orange',\n",
    "    line_alpha=0.7,\n",
    "    line_width=2,\n",
    "    legend_label='Uniform distribution',\n",
    ")\n",
    "\n",
    "plot.yaxis.major_tick_line_color = None\n",
    "plot.yaxis.minor_tick_line_color = None\n",
    "plot.yaxis.major_label_text_font_size = '0pt'\n",
    "plot.outline_line_color = 'black'\n",
    "\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269cfb7-9335-4c7f-92db-43bc7856078a",
   "metadata": {},
   "source": [
    "We can create our `complete-pooling` model in Bean machine using the\n",
    "`@bm.random_variable` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fae37e-b965-491f-b935-6d22a4cb4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bm.random_variable\n",
    "def phi() -> RVIdentifier:\n",
    "    \"\"\"Population's ability for hitting a ball when at bat.\"\"\"\n",
    "    return dist.Beta(1, 1)\n",
    "\n",
    "\n",
    "@bm.random_variable\n",
    "def y(i: int, K: int) -> RVIdentifier:\n",
    "    \"\"\"Chance a player has to make a hit when at-bat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : int\n",
    "        An index.\n",
    "    K : int\n",
    "        Number of trials (at-bats).\n",
    "    \"\"\"\n",
    "    return dist.Binomial(K, phi())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d81883-b434-4377-9ba4-9325dd51171f",
   "metadata": {},
   "source": [
    "In the code cell above we have defined our population prior and chance of\n",
    "landing a hit when at-bat in the top-level namespace of our notebook. Bean\n",
    "Machine can take advantage of creating models as classes as well, and we\n",
    "illustrate how to do that below for our `complete-pooling` model. We will not\n",
    "use the class method for the rest of the tutorial, however, it does show how one\n",
    "could accomplish creating models as class objects in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671400b2-e99e-4274-be42-7959d7c025b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompletePoolingModel:\n",
    "    \"\"\"Example for creating a class object as a Bean Machine model.\"\"\"\n",
    "\n",
    "    @bm.random_variable\n",
    "    def phi(self) -> RVIdentifier:\n",
    "        \"\"\"Population's ability for hitting a ball when at bat.\"\"\"\n",
    "        return dist.Beta()\n",
    "\n",
    "    @bm.random_variable\n",
    "    def y(self, i: int, K: int) -> RVIdentifier:\n",
    "        \"\"\"Chance a player has to make a hit when at-bat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        i : int\n",
    "            An index.\n",
    "        K : int\n",
    "            Number of trials (at-bats).\n",
    "        \"\"\"\n",
    "        return dist.Binomial(K, phi())\n",
    "\n",
    "\n",
    "complete_pooling_model = CompletePoolingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b09db5-0321-46d2-9e44-87e0e81dbb89",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Complete-pooling inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d228ab5-b560-4975-805e-1677d7c79838",
   "metadata": {
    "tags": []
   },
   "source": [
    "We need to supply observational data to our model defined above. Bean Machine's\n",
    "inference algorithms expect observations in the form of a dictionary. This\n",
    "dictionary should consist of `@bm.random_variable` invocations as keys, and\n",
    "tensor data as values. Recall from above that the `@bm.random_variable`\n",
    "decorator allows us to define unique random variables by using a dummy index.\n",
    "Below we use this to our advantage when defining data observations, which are\n",
    "explicitly coded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485f117-f852-40f5-9c81-1b4c22ecb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE The `at_bats` type should be a native Python type since they are used as\n",
    "#      arguments for the observation dictionary keys.\n",
    "at_bats = df['Current at-bats'].astype(int).tolist()\n",
    "\n",
    "# NOTE The `hits` type should be a Tensor type as Bean Machine requires all\n",
    "#      values to be a tensor when executing inference.\n",
    "hits = [tensor(hit) for hit in df['Current hits'].astype(int).tolist()]\n",
    "\n",
    "# NOTE We are explicitly coding the index for `y` in the dictionary.\n",
    "complete_pooling_observations = {\n",
    "    y(0, at_bats[0]): hits[0],\n",
    "    y(1, at_bats[1]): hits[1],\n",
    "    y(2, at_bats[2]): hits[2],\n",
    "    y(3, at_bats[3]): hits[3],\n",
    "    y(4, at_bats[4]): hits[4],\n",
    "    y(5, at_bats[5]): hits[5],\n",
    "    y(6, at_bats[6]): hits[6],\n",
    "    y(7, at_bats[7]): hits[7],\n",
    "    y(8, at_bats[8]): hits[8],\n",
    "    y(9, at_bats[9]): hits[9],\n",
    "    y(10, at_bats[10]): hits[10],\n",
    "    y(11, at_bats[11]): hits[11],\n",
    "    y(12, at_bats[12]): hits[12],\n",
    "    y(13, at_bats[13]): hits[13],\n",
    "    y(14, at_bats[14]): hits[14],\n",
    "    y(15, at_bats[15]): hits[15],\n",
    "    y(16, at_bats[16]): hits[16],\n",
    "    y(17, at_bats[17]): hits[17],\n",
    "}\n",
    "complete_pooling_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d1f2f-60d1-42da-be9e-d2518d87b89f",
   "metadata": {},
   "source": [
    "We are ready to run inference on our model and observations. Bean Machine\n",
    "supports a rich library of inference algorithms that share a common infer\n",
    "method with the following arguments:\n",
    "\n",
    "| Name           | Usage                                                                                         |\n",
    "|----------------|-----------------------------------------------------------------------------------------------|\n",
    "| `queries`      | A list of @bm.random_variable targets to fit posterior distributions for.                     |\n",
    "| `observations` | The Dict of observations we built up, above.                                                  |\n",
    "| `num_samples`  | Number of samples to build up distributions for the values listed in queries.                 |\n",
    "| `num_chains`   | Number of separate inference runs to use. Multiple chains can verify inference ran correctly. |\n",
    "\n",
    "For this particular problem, we will use the `GlobalNoUTurnSampler`\n",
    "inference method. We have chosen to use the NUTS sampler because it can be\n",
    "easily compared to other probabilistic tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6d427-5ce5-433b-bcea-ab1f1352410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pooling_queries = [phi()]\n",
    "complete_pooling_samples = bm.GlobalNoUTurnSampler().infer(\n",
    "    queries=complete_pooling_queries,\n",
    "    observations=complete_pooling_observations,\n",
    "    num_samples=3000,\n",
    "    num_chains=4,\n",
    "    num_adaptive_samples=1500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10ff61-8755-44ed-a563-ea1d500a924d",
   "metadata": {},
   "source": [
    "#### Complete-pooling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060463e-0cd8-4893-8d72-c2e860875853",
   "metadata": {},
   "source": [
    "The `complete_pooling_samples` object contains our inference results. We have\n",
    "only one parameter in this model, $\\phi$, which was supplied as our single query\n",
    "parameter when we ran inference. We can investigate what the posterior\n",
    "distribution looks like, but first let us look at the trace plots for $\\phi$\n",
    "to make sure the model was able to mix well for all chains. Bean machine has a\n",
    "convenient `Diagnostics` attribute that we can use to plot the traces for $\\phi$\n",
    "for each chain, as well as their autocorrelations plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8c681-d9ee-416b-96b0-32b2fd1e62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pooling_query_trace = bm.Diagnostics(complete_pooling_samples).plot(display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a4605-ef9a-4a08-8958-67a7e08ba432",
   "metadata": {},
   "source": [
    "We can see from this figure that the chains mixed well as the trace plot for\n",
    "$\\phi$ does not have any areas where the parameter gets \"stuck\".\n",
    "\n",
    "Below we show two other diagnostic statistics: [$\\hat{R}$](#references) and\n",
    "[$N_\\text{eff}$](#references).\n",
    "\n",
    "  * $\\hat{R} \\in [1, \\infty)$ summarizes how effective inference was at\n",
    "    converging on the correct posterior distribution for a particular random\n",
    "    variable. It uses information from all chains in order to assess\n",
    "    whether inference had a good understanding of the distribution or not.\n",
    "    Values very close to zero indicate that all chains discovered similar\n",
    "    distributions for a particular random variable. We do not recommend using\n",
    "    inference results where $\\hat{R} > 1.1$, as inference may not have\n",
    "    converged. In that case, you may want to run inference for more samples.\n",
    "  * $N_\\text{eff} \\in [1, \\texttt{num}\\_\\texttt{samples}]$ summarizes how\n",
    "    independent posterior samples are from one another. Although inference was\n",
    "    run for `num_samples` iterations, it is possible that those samples were\n",
    "    very similar to each other (due to the way inference is implemented), and\n",
    "    may not be representative of the full posterior space. Larger numbers\n",
    "    are better here, and if your particular use case calls for a certain number\n",
    "    of samples to be considered, you should ensure that $N_\\text{eff}$ is at\n",
    "    least that large.\n",
    "\n",
    "In this case, $\\hat{R}$ and $N_\\text{eff}$ have acceptable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea069a6-51bf-4044-bcee-65a3dc906d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pooling_diagnostics = bm.Diagnostics(complete_pooling_samples)\n",
    "print(f'r_hat: {complete_pooling_diagnostics.split_r_hat(query_list=[phi()]).values[0][0]}')\n",
    "print(f'n_eff: {complete_pooling_diagnostics.effective_sample_size(query_list=[phi()]).values[0][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34368890-4b6a-4bc8-bb2d-d83f97560dbb",
   "metadata": {},
   "source": [
    "Below we see the posterior distribution for $\\phi$. We have a maximum likelihood\n",
    "estimate of 0.27 with 89% of the highest density of the posterior lying between\n",
    "0.24 and 0.29.\n",
    "\n",
    "Why an 89% highest density interval (HDI)? To prevent you from thinking about a\n",
    "95% confidence interval. See [McElreath](#references) for further discussion on\n",
    "this subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c41595-7cfb-42bb-bc4a-46199cac56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pooling_query_plot = az.plot_posterior({'φ': complete_pooling_samples[phi()].numpy()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7219cb23-ad15-4d78-8eca-c86cc7901a8c",
   "metadata": {},
   "source": [
    "What this is telling us from our model and data is that every player will have\n",
    "a 27% chance of hitting a ball when at-bat. So everyone has the same chance to\n",
    "hit a ball when at-bat. This statement's unusualness becomes evident when\n",
    "we plot all the players in the same plot showing their chances of success when\n",
    "at-bat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a128c-0080-4a28-af6e-c35ee7dfddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pooling_data = {'φ': complete_pooling_samples[phi()].numpy()}\n",
    "\n",
    "complete_pooling_hdis = az.hdi(\n",
    "    complete_pooling_data,\n",
    "    hdi_prob=0.89,\n",
    ").to_dataframe().T.rename(columns={'lower': 'hdi_11%', 'higher': 'hdi_89%'})\n",
    "\n",
    "# Calculate the summary statistics for the complete pooling model.\n",
    "complete_pooling_summary_df = az.summary(\n",
    "    complete_pooling_data,\n",
    "    round_to=6,\n",
    "    stat_funcs={'median': np.median},\n",
    "    extend=True,\n",
    ").drop(\n",
    "    ['hdi_5.5%', 'hdi_94.5%'],\n",
    "    axis=1,\n",
    ").join(complete_pooling_hdis)\n",
    "complete_pooling_summary_df['mode'] = np.nan\n",
    "modes = []\n",
    "for complete_pooling_query in complete_pooling_queries:\n",
    "    data = complete_pooling_samples[complete_pooling_query].reshape(-1,).numpy()\n",
    "    kde = sm.nonparametric.KDEUnivariate(data)\n",
    "    kde.fit()\n",
    "    mode = kde.support[np.argmax(kde.density)]\n",
    "    modes.append(mode)\n",
    "complete_pooling_summary_df['mode'] = modes\n",
    "\n",
    "population_mean = (df['Current hits'] / df['Current at-bats']).mean()\n",
    "population_std = (df['Current hits'] / df['Current at-bats']).std()\n",
    "x = (df['Current hits'] / df['Current at-bats']).values\n",
    "posterior_mode = complete_pooling_summary_df['mode'].tolist() * df.shape[0]\n",
    "posterior_upper_hdi = np.array(complete_pooling_summary_df['hdi_89%'].tolist() * df.shape[0])\n",
    "posterior_lower_hdi = np.array(complete_pooling_summary_df['hdi_11%'].tolist() * df.shape[0])\n",
    "\n",
    "complete_pooling_source = ColumnDataSource(\n",
    "    {\n",
    "        'x': x,\n",
    "        'mode': posterior_mode,\n",
    "        'upper_hdi': posterior_upper_hdi,\n",
    "        'lower_hdi': posterior_lower_hdi,\n",
    "        'lower_std': [population_mean - population_std] * df.shape[0],\n",
    "        'upper_std': [population_mean + population_std] * df.shape[0],\n",
    "        'name': df['Name'].values,\n",
    "    }\n",
    ")\n",
    "\n",
    "complete_pooling_plot = figure(\n",
    "    plot_width=500,\n",
    "    plot_height=500,\n",
    "    title='Complete-pooling',\n",
    "    x_axis_label='Observed hits / at-bats',\n",
    "    y_axis_label='Predicted chance of a hit',\n",
    "    y_range=[0.05, 0.55],\n",
    "    x_range=[0.14, 0.41],\n",
    ")\n",
    "mean_line = complete_pooling_plot.line(\n",
    "    x=[0, 1],\n",
    "    y=[population_mean, population_mean],\n",
    "    line_color='orange',\n",
    "    line_width=3,\n",
    "    level='underlay',\n",
    "    legend_label='Population mean',\n",
    ")\n",
    "std_band = Band(\n",
    "    base='x',\n",
    "    lower='lower_std',\n",
    "    upper='upper_std',\n",
    "    source=complete_pooling_source,\n",
    "    level='underlay',\n",
    "    fill_alpha=0.2,\n",
    "    fill_color='orange',\n",
    "    line_width=0.2,\n",
    "    line_color='orange',\n",
    ")\n",
    "complete_pooling_plot.add_layout(std_band)\n",
    "complete_pooling_whiskers = Whisker(\n",
    "    base='x',\n",
    "    upper='upper_hdi',\n",
    "    lower='lower_hdi',\n",
    "    source=complete_pooling_source,\n",
    "    line_color='steelblue',\n",
    ")\n",
    "complete_pooling_whiskers.upper_head.line_color = 'steelblue'\n",
    "complete_pooling_whiskers.lower_head.line_color = 'steelblue'\n",
    "complete_pooling_plot.add_layout(complete_pooling_whiskers)\n",
    "complete_pooling_glyph = complete_pooling_plot.circle(\n",
    "    x='x',\n",
    "    y='mode',\n",
    "    source=complete_pooling_source,\n",
    "    size=10,\n",
    "    line_color='white',\n",
    "    fill_color='steelblue',\n",
    "    legend_label='Players',\n",
    ")\n",
    "complete_pooling_tooltips = HoverTool(\n",
    "    renderers=[complete_pooling_glyph],\n",
    "    tooltips=[\n",
    "        ('Name', '@name'),\n",
    "        ('Posterior Upper HDI', '@upper_hdi{0.000}'),\n",
    "        ('Posterior Mode', '@mode{0.000}'),\n",
    "        ('Posterior Lower HDI', '@lower_hdi{0.000}'),\n",
    "    ],\n",
    ")\n",
    "complete_pooling_plot.add_tools(complete_pooling_tooltips)\n",
    "\n",
    "complete_pooling_plot.legend.location = 'top_left'\n",
    "complete_pooling_plot.legend.click_policy = 'mute'\n",
    "\n",
    "show(complete_pooling_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48876a5-78b1-4106-95de-0c1de9489f22",
   "metadata": {},
   "source": [
    "The above plot shows our predictions for each player's chance of hitting a ball\n",
    "when at-bat, with error bars being the 89% HDI and the scatter plot being the\n",
    "maximum likelihood of the posterior (mode). The orange horizontal line shows\n",
    "the mean, and the orange box shows the standard deviation for the actual data.\n",
    "\n",
    "Our data story said that every player is unique, but we have not captured that\n",
    "information as the plot shows that every player is the same. The model also\n",
    "tells us that poor hitting players are just as likely to land a hit when at-bat\n",
    "than very good hitting players. Recall that at the beginning of this section we\n",
    "stated that this type of model will overestimate player's abilities that hit\n",
    "poorly while underestimating player's abilities that hit well. We will revisit\n",
    "this in the next section, but take note that this is the case.\n",
    "\n",
    "In hindsight our complete pooling model may seem trivial in that we\n",
    "successfully obtained the mean and its standard deviation through a\n",
    "probabilistic programming manner. Why would we do this when we can calculate\n",
    "the mean and the standard deviation from the given data and get pretty close to\n",
    "the values we would calculate using a PPL technique? Well, we can do better,\n",
    "but before we do better we are going to make another model that is equally as\n",
    "bad as our complete pooling one. The reason why we do this will be come evident\n",
    "when we get to our third and final model the [partial-pooling\n",
    "model](#partial-pooling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54b73d-60c0-407e-998a-76b36e3e8a2a",
   "metadata": {},
   "source": [
    "<a id=\"no-pooling\"></a>\n",
    "### No-pooling model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9c6d0-2f82-4d88-bee9-8d745a23a273",
   "metadata": {},
   "source": [
    "`No-pooling` is the polar opposite to `complete-pooling`, where instead of\n",
    "treating each player identically, we will treat each player as having their own\n",
    "separate chance of landing a hit when at-bat. Essentially we will be creating a\n",
    "model for each player and each model will have no influence on any of the other\n",
    "models. We will see later on that choosing a `no-pooling` model overestimates\n",
    "top batter's abilities while underestimating poor batter's abilities. Note that\n",
    "this is the opposite to what the `complete-pooling` model did and to our data\n",
    "story that says players are _similar_ not exactly unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e921604-dbf6-4de9-a3ed-f0f850261f5a",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img src=\"img/no-pooling.svg\">\n",
    "</center>\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\theta&\\sim\\text{Beta}(1, 1)\\\\\n",
    "  y&\\sim\\text{Binomial}(K, \\theta)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac4895-dace-4c10-8f11-e8e82587153f",
   "metadata": {},
   "source": [
    "The above graph shows what a `no-pooling` model does. Each player has a\n",
    "separate model (the $\\theta$s) and no information about a player is shared\n",
    "within the group. This type of model assumes every player is uniquely\n",
    "different.\n",
    "\n",
    "We will use Bean Machine to create this type of model as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99faee7-8eee-4275-9b43-df5973024a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bm.random_variable\n",
    "def theta(i: int) -> RVIdentifier:\n",
    "    \"\"\"An individual player's ability for landing a hit when at-bat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : int\n",
    "        An index.\n",
    "    \"\"\"\n",
    "    return dist.Beta(1, 1)\n",
    "\n",
    "\n",
    "@bm.random_variable\n",
    "def y(i: int, K: int) -> RVIdentifier:\n",
    "    \"\"\"An individual player's chances of hitting a ball when at-bat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : int\n",
    "        An index.\n",
    "    K : int\n",
    "        Number of trials (at-bats).\n",
    "    \"\"\"\n",
    "    return dist.Binomial(K, theta(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30627b9f-835c-432e-a759-39b23f9da9b9",
   "metadata": {},
   "source": [
    "How to code the `no-pooling` model and how to code the `complete-pooling` model\n",
    "are quite similar. Note that the difference between the two models is that we\n",
    "have introduced an index $i$ for both random variables. The index value is used\n",
    "to create a family of distributions, which is what we need since we are now\n",
    "creating 18 different models, one for each player we have data for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9705a059-b1bd-4631-8632-d1fcb87d4615",
   "metadata": {},
   "source": [
    "#### No-pooling inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec0e5b-c945-4a3a-ba72-8b9c04c812a9",
   "metadata": {},
   "source": [
    "Just like before we will use the `GlobalNoUTurnSampler` inference\n",
    "method. We construct the observations dictionary similarly to how we\n",
    "constructed it in the `complete-pooling` model, except now we will construct\n",
    "the dictionary in a more compact manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9b661-9d89-4e38-a8eb-0cf86802cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_bats = [\n",
    "    y(i, at_bat)\n",
    "    for i, at_bat in enumerate(df['Current at-bats'].astype(int).tolist())\n",
    "]\n",
    "no_pooling_observations = dict(zip(at_bats, hits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b19b27-5d4e-4213-bca0-38a0d673fec3",
   "metadata": {},
   "source": [
    "The queries we are interested in from this model are all the $\\theta$'s as they\n",
    "are the distributions for each player's individual ability. We created a family\n",
    "of distributions using Bean machine by adding the index $i$ to each random\n",
    "variable. Now we will use that index to our advantage and use it to create a\n",
    "list of queries, all of which are the $\\theta$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cb789-8f33-47df-8579-e27539ba1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pooling_queries = [theta(i) for i in df.index]\n",
    "no_pooling_samples = bm.GlobalNoUTurnSampler().infer(\n",
    "    queries=no_pooling_queries,\n",
    "    observations=no_pooling_observations,\n",
    "    num_samples=3000,\n",
    "    num_chains=4,\n",
    "    num_adaptive_samples=1500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c86c8-9a02-4ab8-abe8-15c408d87d6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### No-pooling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a398f2-4efb-494f-a678-4672f8cf3a39",
   "metadata": {},
   "source": [
    "Again we will start our analysis of our no pooling model with summary statistics\n",
    "and trace plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f93230-d924-44ac-a927-2479d0da5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pooling_theta_traces = bm.Diagnostics(no_pooling_samples).plot(display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb881a-7a0a-41e0-ae0a-3801dc1968e7",
   "metadata": {},
   "source": [
    "All the trace plots look like they have mixed well. Next we check the $\\hat{R}$\n",
    "and $N_{eff}$ values for each $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9abf8a-6411-4edf-887b-dbe2140de5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pooling_diagnostics = bm.Diagnostics(no_pooling_samples)\n",
    "data = []\n",
    "for index, name in df['Name'].iteritems():\n",
    "    data.append(\n",
    "        {\n",
    "            'query': f'θ[{name}]',\n",
    "            'r_hat': no_pooling_diagnostics.split_r_hat(query_list=[theta(index)]).values[0][0],\n",
    "            'n_eff': no_pooling_diagnostics.effective_sample_size(query_list=[theta(index)]).values[0][0],\n",
    "        }\n",
    "    )\n",
    "no_pooling_bm_summary = pd.DataFrame.from_dict(data).set_index('query')\n",
    "no_pooling_bm_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e9739-c419-41f0-bbec-1fd9ce24c9e8",
   "metadata": {},
   "source": [
    "The above values for each model look great. Next we plot the posterior values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9043f5a-493c-4b16-aba7-336f1dfefd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pooling_data = {\n",
    "    f'θ[{name}]': no_pooling_samples[theta(i)].numpy()\n",
    "    for i, name in df['Name'].iteritems()\n",
    "}\n",
    "no_pooling_query_plot = az.plot_posterior(no_pooling_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7f90e-31a0-471e-9442-ced7320f49cf",
   "metadata": {},
   "source": [
    "Both the trace plots and the summary statistics show that we have good mixing\n",
    "between the chains. Just like in the complete pooling model analysis, we will\n",
    "plot each of the player's abilities on a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06695059-8cad-45c7-bd21-c8e37050f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pooling_hdis = az.hdi(\n",
    "    no_pooling_data,\n",
    "    hdi_prob=0.89,\n",
    ").to_dataframe().T.rename(columns={'lower': 'hdi_11%', 'higher': 'hdi_89%'})\n",
    "no_pooling_summary_df = az.summary(\n",
    "    no_pooling_data,\n",
    "    round_to=6,\n",
    "    stat_funcs={'median': np.median},\n",
    "    extend=True,\n",
    ").drop(['hdi_5.5%', 'hdi_94.5%'], axis=1).join(no_pooling_hdis)\n",
    "no_pooling_summary_df['mode'] = np.nan\n",
    "modes = []\n",
    "for no_pooling_query in no_pooling_queries:\n",
    "    data = no_pooling_samples[no_pooling_query].reshape(-1,).numpy()\n",
    "    kde = sm.nonparametric.KDEUnivariate(data)\n",
    "    kde.fit()\n",
    "    mode = kde.support[np.argmax(kde.density)]\n",
    "    modes.append(mode)\n",
    "no_pooling_summary_df['mode'] = modes\n",
    "\n",
    "x = (df['Current hits'] / df['Current at-bats']).values\n",
    "posterior_mode = no_pooling_summary_df['mode'].values\n",
    "posterior_upper_hdi = no_pooling_summary_df['hdi_89%']\n",
    "posterior_lower_hdi = no_pooling_summary_df['hdi_11%']\n",
    "\n",
    "no_pooling_source = ColumnDataSource(\n",
    "    {\n",
    "        'x': x,\n",
    "        'mode': posterior_mode,\n",
    "        'upper_hdi': posterior_upper_hdi,\n",
    "        'lower_hdi': posterior_lower_hdi,\n",
    "        'name': df['Name'].values,\n",
    "    }\n",
    ")\n",
    "\n",
    "no_pooling_plot = figure(\n",
    "    plot_width=500,\n",
    "    plot_height=500,\n",
    "    title='No pooling',\n",
    "    x_axis_label='Observed hits / at-bats',\n",
    "    y_axis_label='Predicted chance of a hit',\n",
    "    x_range=[0.14, 0.41],\n",
    "    y_range=[0.05, 0.55],\n",
    ")\n",
    "\n",
    "mean_line = no_pooling_plot.line(\n",
    "    x=[0, 1],\n",
    "    y=[population_mean, population_mean],\n",
    "    line_color='orange',\n",
    "    line_width=3,\n",
    "    level='underlay',\n",
    "    legend_label='Population mean',\n",
    ")\n",
    "\n",
    "straight_line = no_pooling_plot.line(\n",
    "    x=x,\n",
    "    y=(df['Current hits'] / df['Current at-bats']).values,\n",
    "    line_color='grey',\n",
    "    line_alpha=0.7,\n",
    "    line_width=2.0,\n",
    "    legend_label='Current hits / Current at-bats',\n",
    ")\n",
    "\n",
    "no_pooling_whiskers = Whisker(\n",
    "    base='x',\n",
    "    upper='upper_hdi',\n",
    "    lower='lower_hdi',\n",
    "    source=no_pooling_source,\n",
    "    line_color='steelblue',\n",
    ")\n",
    "no_pooling_whiskers.upper_head.line_color = 'steelblue'\n",
    "no_pooling_whiskers.lower_head.line_color = 'steelblue'\n",
    "no_pooling_plot.add_layout(no_pooling_whiskers)\n",
    "\n",
    "no_pooling_glyph = no_pooling_plot.circle(\n",
    "    x='x',\n",
    "    y='mode',\n",
    "    source=no_pooling_source,\n",
    "    size=10,\n",
    "    line_color='white',\n",
    "    fill_color='steelblue',\n",
    "    legend_label='Players',\n",
    ")\n",
    "\n",
    "no_pooling_tooltips = HoverTool(\n",
    "    renderers=[no_pooling_glyph],\n",
    "    tooltips=[\n",
    "        ('Name', '@name'),\n",
    "        ('Posterior Upper HDI', '@upper_hdi{0.000}'),\n",
    "        ('Posterior Mode', '@mode{0.000}'),\n",
    "        ('Posterior Lower HDI', '@lower_hdi{0.000}'),\n",
    "    ],\n",
    ")\n",
    "no_pooling_plot.add_tools(no_pooling_tooltips)\n",
    "\n",
    "no_pooling_plot.add_layout(std_band)\n",
    "\n",
    "no_pooling_plot.legend.location = 'top_left'\n",
    "no_pooling_plot.legend.click_policy = 'mute'\n",
    "\n",
    "show(gridplot([[complete_pooling_plot, no_pooling_plot]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109809d4-0023-4716-8916-a4ddb9373eec",
   "metadata": {},
   "source": [
    "In the above plot we we show the predicted chance of landing a hit when at-bat\n",
    "for our first two models. As we stated in the\n",
    "[complete-pooling](#complete-pooling) section this model overestimates week\n",
    "hitting player's abilities and underestimates good hitting player's abilities.\n",
    "This effect is quite apparent when looking at the no-pooling plot to the right.\n",
    "In the no-pooling plot we again plot posterior maximum likelihood for each\n",
    "player and the error bars show the central 89% posterior interval (HDI). The\n",
    "grey line is discussed below.\n",
    "\n",
    "The player's abilities for the no-pooling model show a wide spread from 0.15 to\n",
    "0.399. It turns out that a hitting average for MLB players in the high 300s is\n",
    "quite rare, see [Wikipedia (All-time-players)](#references) for historical\n",
    "context. So, we in fact see that this model does what we initially said: it\n",
    "would underestimate poor player's ability to hit when at-bat and overestimate\n",
    "highly successful player's ability when at-bat. Recall that this statement is\n",
    "the exact opposite to what the complete-pooling model did.\n",
    "\n",
    "So far we have not done a good job of telling our data story through our models.\n",
    "Our complete-pooling model said every player was the same, while our no-pooling\n",
    "model said all players are uniquely different. However, our data story said\n",
    "that all players are different, but similar. What we have done so far is to\n",
    "model the extreme cases for our data. In the next section we will combine these\n",
    "two models such that we have a more accurate representation of player's\n",
    "abilities and their chances of success when at-bat.\n",
    "\n",
    "The grey line is found by setting\n",
    "\n",
    "$$\n",
    "y = \\frac{\\text{Current hits}}{\\text{Current at-bats}}.\n",
    "$$\n",
    "\n",
    "Since this is also our x-axis, we have a straight line. Just like in our\n",
    "complete-pooling model where we discovered the population mean through a\n",
    "probabliistic programming manner, we have done the same thing with our\n",
    "no-pooling model. Except in this model we have discovered the posteriors\n",
    "follow the line made by the above fraction, which can be directly calculated\n",
    "from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c5b28-2cbf-4aa5-9a93-ee8b0ce4b3c5",
   "metadata": {},
   "source": [
    "<a id=\"parital-pooling\"></a>\n",
    "### Partial-pooling model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813edf22-3d82-440b-9b99-8d9ac7ff3134",
   "metadata": {},
   "source": [
    "Partial pooling combines [complete-pooling](#complete-pooling) and\n",
    "[no-pooling](#no-pooling) models to create a hybrid model that creates separate\n",
    "models for each player _and simultaneously_ estimates the population's\n",
    "abilities. Remember we do not have any data on the MLB population, but we can\n",
    "still create estimates of it. The partial-pooling model does a better job of\n",
    "estimating all batter's abilities using information about the population. It\n",
    "will also do a better job of not underestimating poor hitter's abilities and not\n",
    "overestimating good hitter's abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765015d-f2ab-4a0b-922f-4fad99109b50",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <img src=\"img/partial-pooling.svg\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6daf0b6-5ed2-4403-a346-fcaf3ddc8473",
   "metadata": {},
   "source": [
    "The above image shows that each player has their own chance of hitting when\n",
    "at-bat ($\\theta$) and that each $\\theta$ is being sampled from a population\n",
    "distribution $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf0ffc-7b25-42bf-9eb8-6fb9c36751a7",
   "metadata": {},
   "source": [
    "In the partial-pooling model we are again modeling each player separately since\n",
    "each player is given their own individual chance of getting a hit when at-bat\n",
    "($\\theta$) just like the no-pooling model.  The new thing about this model is\n",
    "that we now connect each player's chance of getting a hit to a population\n",
    "parameter $\\phi$, which is similar to what we did in the complete-pooling\n",
    "model. Our model is then\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\phi&\\sim\\text{Beta}(1, 1)\\\\\n",
    "  \\kappa&\\sim\\text{Pareto}(1, 1.5)\\\\\n",
    "  \\theta&\\sim\\text{Beta}(\\phi * \\kappa, (1- \\phi) * \\kappa)\\\\\n",
    "  y&\\sim\\text{Binomial}(K, \\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "From the graphical representation, we can see that a partial-pooling model is\n",
    "combining a complete- and no-pooling model together. The new component of the\n",
    "model is the $\\kappa$ parameter, which is sampled from a `Pareto` distribution.\n",
    "$\\kappa$ has been introduced to this model because $\\theta$, the distribution\n",
    "for each player's chance of getting a hit when at-bat, has priors $\\alpha$ and\n",
    "$\\beta$, which both need to be estimated. For a more thourough discussion about\n",
    "$\\kappa$, see [Carpenter 2016](#references).\n",
    "\n",
    "A few plots of the Pareto distribution with varying parameters are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af821d7-ad16-4f4a-ab61-521e6aaf774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = figure(\n",
    "    plot_width=400,\n",
    "    plot_height=400,\n",
    "    title='Pareto distribution',\n",
    "    x_axis_label='Support',\n",
    "    x_range=[0, 5],\n",
    ")\n",
    "colors = ['steelblue', 'orange', 'brown', 'magenta']\n",
    "\n",
    "for i, alpha in enumerate(np.linspace(start=1.5, stop=3, num=4)):\n",
    "    pareto = dist.Pareto(tensor(1.), tensor(float(alpha)))\n",
    "    pareto_samples = pareto.sample((N,))\n",
    "    pareto_kde = sm.nonparametric.KDEUnivariate(pareto_samples)\n",
    "    pareto_kde.fit()\n",
    "\n",
    "    pareto_source = ColumnDataSource(\n",
    "        {\n",
    "            'x': pareto_kde.support,\n",
    "            'y': pareto_kde.density / pareto_kde.density.max(),\n",
    "        }\n",
    "    )\n",
    "    pareto_glyph = plot.line(\n",
    "        x='x',\n",
    "        y='y',\n",
    "        source=pareto_source,\n",
    "        line_color=colors[i],\n",
    "        line_alpha=0.7,\n",
    "        line_width=2,\n",
    "        legend_label=f'α = {alpha}',\n",
    "    )\n",
    "\n",
    "plot.yaxis.major_tick_line_color = None\n",
    "plot.yaxis.minor_tick_line_color = None\n",
    "plot.yaxis.major_label_text_font_size = '0pt'\n",
    "plot.outline_line_color = 'black'\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bcec1e-1b0b-4e5a-8aa7-3a07d66f7780",
   "metadata": {},
   "source": [
    "We can code our partial pooling model easily in Bean Machine. All we need to do\n",
    "is reintroduce $\\phi$ as our estimate for the population's ability for hitting\n",
    "a ball when at-bat, and our new model for each individual's abilty for successfully\n",
    "hitting when at-bat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fa058-3e8b-431c-81ec-61922824d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bm.random_variable\n",
    "def phi() -> RVIdentifier:\n",
    "    \"\"\"The population's overall abiltity to hit a ball when at-bat.\"\"\"\n",
    "    return dist.Beta(1, 1)\n",
    "\n",
    "\n",
    "@bm.random_variable\n",
    "def kappa() -> RVIdentifier:\n",
    "    \"\"\"Hyperprior for theta.\"\"\"\n",
    "    return dist.Pareto(1, 1.5)\n",
    "\n",
    "\n",
    "@bm.random_variable\n",
    "def theta(i: int) -> RVIdentifier:\n",
    "    \"\"\"An individual's ability to hit a ball when at-bat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : int\n",
    "        An index.\n",
    "    \"\"\"\n",
    "    alpha = phi() * kappa()\n",
    "    beta = (1 - phi()) * kappa()\n",
    "    return dist.Beta(alpha, beta)\n",
    "\n",
    "\n",
    "@bm.random_variable\n",
    "def y(i: int, K: int) -> RVIdentifier:\n",
    "    \"\"\"Chance of hitting when at-bat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : int\n",
    "        An index.\n",
    "    K : int\n",
    "        Number of trials (at-bats).\n",
    "    \"\"\"\n",
    "    return dist.Binomial(K, theta(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e131ae3-40e9-4c72-b991-68d5723c86d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Partial-pooling inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b640bb-f16b-4f2e-befb-b678b55c7a31",
   "metadata": {},
   "source": [
    "Again we construct our observations into a dictionary, and sample using the\n",
    "`GlobalNoUTurnSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f33a5a-c9ae-46c3-9156-80a5aba5ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling_observations = dict(zip(at_bats, hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77b188-442d-4f2b-bc1c-7f6592d73eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling_queries =  [kappa(), phi()] + [theta(i) for i in df.index]\n",
    "partial_pooling_samples = bm.GlobalNoUTurnSampler().infer(\n",
    "    queries=partial_pooling_queries,\n",
    "    observations=partial_pooling_observations,\n",
    "    num_samples=3000,\n",
    "    num_chains=4,\n",
    "    num_adaptive_samples=1500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540379d-555f-45dd-8780-574dda0b5af2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Partial-pooling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce224aeb-3567-49cc-881e-a4e732e12b19",
   "metadata": {},
   "source": [
    "All the trace plots and their autocorrelation plots look good. You should\n",
    "investigate the trace plot for $\\kappa$ and notice the differences between its\n",
    "trace plot and the trace plots for the $\\theta$s. Recall that we required\n",
    "$\\kappa$ to always be greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0f3c3-b0c8-40bd-9b6f-63211c601f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling_traces = bm.Diagnostics(partial_pooling_samples).plot(display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ea896-c8e3-4a14-851b-df35e137279c",
   "metadata": {},
   "source": [
    "Again we will look at the $\\hat{R}$ and $N_{eff}$ values for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e8e1a-d6e4-46b7-8de5-2c21b968da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling_diagnostics = bm.Diagnostics(partial_pooling_samples)\n",
    "partial_pooling_summary_data = []\n",
    "partial_pooling_summary_data.append(\n",
    "    {\n",
    "        'query': 'κ',\n",
    "        'r_hat': partial_pooling_diagnostics.split_r_hat(query_list=[kappa()]).values[0][0],\n",
    "        'n_eff': partial_pooling_diagnostics.effective_sample_size(query_list=[kappa()]).values[0][0],\n",
    "    }\n",
    ")\n",
    "partial_pooling_summary_data.append(\n",
    "    {\n",
    "        'query': 'φ',\n",
    "        'r_hat': partial_pooling_diagnostics.split_r_hat(query_list=[phi()]).values[0][0],\n",
    "        'n_eff': partial_pooling_diagnostics.effective_sample_size(query_list=[phi()]).values[0][0],\n",
    "    }\n",
    ")\n",
    "for index, name in df['Name'].iteritems():\n",
    "    partial_pooling_summary_data.append(\n",
    "        {\n",
    "            'query': f'θ[{name}]',\n",
    "            'r_hat': partial_pooling_diagnostics.split_r_hat(query_list=[theta(index)]).values[0][0],\n",
    "            'n_eff': partial_pooling_diagnostics.effective_sample_size(query_list=[theta(index)]).values[0][0],\n",
    "        }\n",
    "    )\n",
    "partial_pooling_bm_summary_df = pd.DataFrame.from_dict(partial_pooling_summary_data).set_index('query')\n",
    "partial_pooling_bm_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a608afd-34b2-409d-a9ec-9a7332bfcfc8",
   "metadata": {},
   "source": [
    "These all look good so we will investigate the shapes of the posteriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7de406-148a-4ae4-9ee7-1b13cc303503",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling_posteriror_data = {\n",
    "    'κ': partial_pooling_samples[kappa()].numpy(),\n",
    "    'φ': partial_pooling_samples[phi()].numpy(),\n",
    "}\n",
    "for i, name in df['Name'].iteritems():\n",
    "    partial_pooling_posteriror_data.update({f'θ[{name}]': partial_pooling_samples[theta(i)].numpy()})\n",
    "partial_pooling_query_plot = az.plot_posterior(partial_pooling_posteriror_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab084ba3-bb1e-4032-bff0-2ac60b841db3",
   "metadata": {},
   "source": [
    "All the posteriors look good as well. We will plot the results of our\n",
    "partial-pooling model in a scatter plot, just like we did for the other two\n",
    "models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a24a04-aeb7-43c5-8588-6ff745320cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling_hdis = az.hdi(\n",
    "    partial_pooling_posteriror_data,\n",
    "    hdi_prob=0.89,\n",
    ").to_dataframe().T.rename(columns={'lower': 'hdi_11%', 'higher': 'hdi_89%'})\n",
    "partial_pooling_summary_df = az.summary(\n",
    "    partial_pooling_posteriror_data,\n",
    "    round_to=6,\n",
    "    stat_funcs={'median': np.median},\n",
    "    extend=True,\n",
    ").drop(['hdi_5.5%', 'hdi_94.5%'], axis=1).join(partial_pooling_hdis)\n",
    "partial_pooling_summary_df['mode'] = np.nan\n",
    "modes = []\n",
    "for partial_pooling_query in partial_pooling_queries:\n",
    "    data = partial_pooling_samples[partial_pooling_query].reshape(-1,).numpy()\n",
    "    kde = sm.nonparametric.KDEUnivariate(data)\n",
    "    kde.fit()\n",
    "    mode = kde.support[np.argmax(kde.density)]\n",
    "    modes.append(mode)\n",
    "partial_pooling_summary_df['mode'] = modes\n",
    "\n",
    "partial_pooling_source = ColumnDataSource(\n",
    "    {\n",
    "        'x': x,\n",
    "        'mode': partial_pooling_summary_df.reset_index().loc[2:, 'mode'].values,\n",
    "        'upper_hdi': partial_pooling_summary_df.reset_index().loc[2:, 'hdi_89%'],\n",
    "        'lower_hdi': partial_pooling_summary_df.reset_index().loc[2:, 'hdi_11%'],\n",
    "        'name': df['Name'].values,\n",
    "    }\n",
    ")\n",
    "\n",
    "partial_pooling_plot = figure(\n",
    "    plot_width=500,\n",
    "    plot_height=500,\n",
    "    title='Partial pooling',\n",
    "    x_axis_label='Observed hits / at-bats',\n",
    "    y_axis_label='Predicted chance of a hit',\n",
    "    x_range=[0.14, 0.41],\n",
    "    y_range=[0.05, 0.55],\n",
    ")\n",
    "\n",
    "mean_line = partial_pooling_plot.line(\n",
    "    x=[0, 1],\n",
    "    y=[population_mean, population_mean],\n",
    "    line_color='orange',\n",
    "    line_width=3,\n",
    "    level='underlay',\n",
    "    legend_label='Population mean',\n",
    ")\n",
    "\n",
    "straight_line = partial_pooling_plot.line(\n",
    "    x=x,\n",
    "    y=(df['Current hits'] / df['Current at-bats']).values,\n",
    "    line_color='grey',\n",
    "    line_alpha=0.7,\n",
    "    line_width=2.0,\n",
    "    legend_label='Current hits / Current at-bats',\n",
    ")\n",
    "\n",
    "partial_pooling_whiskers = Whisker(\n",
    "    base='x',\n",
    "    upper='upper_hdi',\n",
    "    lower='lower_hdi',\n",
    "    source=partial_pooling_source,\n",
    "    line_color='steelblue',\n",
    ")\n",
    "partial_pooling_whiskers.upper_head.line_color = 'steelblue'\n",
    "partial_pooling_whiskers.lower_head.line_color = 'steelblue'\n",
    "partial_pooling_plot.add_layout(partial_pooling_whiskers)\n",
    "\n",
    "partial_pooling_glyph = partial_pooling_plot.circle(\n",
    "    x='x',\n",
    "    y='mode',\n",
    "    source=partial_pooling_source,\n",
    "    size=10,\n",
    "    line_color='white',\n",
    "    fill_color='steelblue',\n",
    "    legend_label='Players',\n",
    ")\n",
    "partial_pooling_tooltips = HoverTool(\n",
    "    renderers=[partial_pooling_glyph],\n",
    "    tooltips=[\n",
    "        ('Name', '@name'),\n",
    "        ('Posterior Upper HDI', '@upper_hdi{0.000}'),\n",
    "        ('Posterior Mode', '@mode{0.000}'),\n",
    "        ('Posterior Lower HDI', '@lower_hdi{0.000}'),\n",
    "    ],\n",
    ")\n",
    "partial_pooling_plot.add_tools(partial_pooling_tooltips)\n",
    "partial_pooling_plot.add_layout(std_band)\n",
    "\n",
    "\n",
    "partial_pooling_plot.legend.location = 'top_left'\n",
    "partial_pooling_plot.legend.click_policy = 'mute'\n",
    "\n",
    "show(\n",
    "    gridplot(\n",
    "        [\n",
    "            [complete_pooling_plot, no_pooling_plot],\n",
    "            [partial_pooling_plot],\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa77e97-e055-4ac1-ac4c-f2bd8064ab0d",
   "metadata": {},
   "source": [
    "The partial-pooling model has shifted our predictions. In fact, it has captured\n",
    "our data story, which stated that MLB players are unique (they do not lie on the\n",
    "population mean orange line) and yet they are not all that different (they do\n",
    "not fall on the grey line). What we see is that player's chances of hitting a\n",
    "ball when at-bat have moved closer to the mean line from their positions in the\n",
    "no-pooling model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942a98b-2d8b-4fbc-b7bb-1c4614495b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_pooling_tomean_plot = figure(\n",
    "    plot_width=500,\n",
    "    plot_height=500,\n",
    "    title='Partial pooling shift',\n",
    "    x_axis_label='Observed hits / at-bats',\n",
    "    y_axis_label='Predicted chance of a hit',\n",
    "    x_range=[0.14, 0.41],\n",
    "    y_range=[0.05, 0.55],\n",
    ")\n",
    "mean_line = partial_pooling_tomean_plot.line(\n",
    "    x=[0, 1],\n",
    "    y=[population_mean, population_mean],\n",
    "    line_color='orange',\n",
    "    line_width=3,\n",
    "    level='underlay',\n",
    "    legend_label='Population mean',\n",
    ")\n",
    "straight_line = partial_pooling_tomean_plot.line(\n",
    "    x=x,\n",
    "    y=(df['Current hits'] / df['Current at-bats']).values,\n",
    "    line_color='grey',\n",
    "    line_alpha=0.7,\n",
    "    line_width=2.0,\n",
    "    legend_label='Current hits / Current at-bats',\n",
    ")\n",
    "\n",
    "np_glyph = partial_pooling_tomean_plot.circle(\n",
    "    x='x',\n",
    "    y='mode',\n",
    "    source=no_pooling_source,\n",
    "    size=10,\n",
    "    line_color='steelblue',\n",
    "    fill_color='white',\n",
    "    legend_label='No-pooling',\n",
    ")\n",
    "partial_pooling_tomean_plot.add_layout(partial_pooling_glyph)\n",
    "for i, name in df['Name'].iteritems():\n",
    "    partial_pooling_tomean_plot.add_layout(\n",
    "        Arrow(\n",
    "            end=VeeHead(size=10),\n",
    "            x_start=no_pooling_source.data['x'][i],\n",
    "            y_start=no_pooling_source.data['mode'][i],\n",
    "            x_end=partial_pooling_source.data['x'][i],\n",
    "            y_end=partial_pooling_source.data['mode'][i],\n",
    "        )\n",
    "    )\n",
    "\n",
    "partial_pooling_tomean_plot.add_layout(std_band)\n",
    "partial_pooling_tomean_plot.legend.location = 'top_left'\n",
    "partial_pooling_tomean_plot.legend.click_policy = 'mute'\n",
    "\n",
    "show(partial_pooling_tomean_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beeea6f-79f2-424b-846b-4396453d77f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a2b39-39fb-45fa-85bc-2d6393e81e05",
   "metadata": {},
   "source": [
    "To sum up\n",
    "\n",
    "* Our complete-pooling model\n",
    "\n",
    "  * overestimated a player's chance of landing a hit if the player hits poorly\n",
    "  * understimated a player's chance of landing a hit if the player hits well\n",
    "  * gave us maximum likelihood estimates within the population mean.\n",
    "\n",
    "\n",
    "* Our no-pooling model\n",
    "\n",
    "  * underestimated a player's chance of landing a hit if the player hits poorly\n",
    "  * overstimated a player's chance of landing a hit if the player hits well.\n",
    "\n",
    "\n",
    "* Our partial-pooling model\n",
    "\n",
    "  * estimated a player's chance of landing a hit regardless if they hit poorly\n",
    "    or well.\n",
    "\n",
    "\n",
    "With our limited data we were able to create a model that gives us a player's\n",
    "chance of success when at-bat. Bayesian inference has given us a way to make\n",
    "more accurate predictions about a player's chance of success with a small data\n",
    "set and Bean Machine made creating those models very easy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedcb24-22c0-4ee9-ab93-43e7bf462484",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"references\"></a>\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aac331-cbea-4e5d-aa82-315f15bd29a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Carpenter B (2016) Hierarchical Partial Pooling for Repeated Binary Trials.\n",
    "  [https://mc-stan.org/users/documentation/case-studies/pool-binary-trials.html](https://mc-stan.org/users/documentation/case-studies/pool-binary-trials.html)\n",
    "* Efron B and Morris C (1975) Data analysis using Stein's estimator and its\n",
    "  generalizations. _Journal of the American Statistical Association_ **70**(350),\n",
    "  311–319 [doi: 10.1080/01621459.1975.10479864](https://dx.doi.org/10.1080/01621459.1975.10479864).\n",
    "* Efron B and Morris C (1977) Stein's Paradox in Statistics. _Scientific\n",
    "  American_ **236**(5), 119–127 [JSTOR](https://www.jstor.org/stable/24954030).\n",
    "* McElreath R (2020) **Statistical Rethinking: A Bayesian Course with Examples\n",
    "  in R and Stan** 2nd edition. Chapman and Hall/CRC.\n",
    "  [doi: 10.1201/9780429029608](https://dx.doi.org/10.1201/9780429029608)\n",
    "* $N_{\\text{eff}}$ [MCMC Handbook](https://www.mcmchandbook.net/HandbookChapter1.pdf)\n",
    "* $\\hat{R}$ [Project Euclid](https://projecteuclid.org/euclid.ss/1177011136)\n",
    "* Tarone RE (1982) The use of historical control information in testing for a\n",
    "  trend in proportions. _Biometrics_ **38**(1):215–220\n",
    "  [doi: 10.2307/2530304](https://doi.org/10.2307/2530304)\n",
    "  [doi: 10.1214/20-BA1221](https://dx.doi.org/10.1214/20-BA1221)\n",
    "* [Wikipedia (All-time-players)](https://en.wikipedia.org/wiki/Batting_average_(baseball)#All-time_leaders)\n",
    "* [Wikipedia (Bernoulli trials)](https://en.wikipedia.org/wiki/Bernoulli_trial)\n",
    "* [Wikipedia (Binomial)](https://en.wikipedia.org/wiki/Binomial_distribution)\n",
    "* [Wikipedia (Major League Baseball)](https://en.wikipedia.org/wiki/Major_League_Baseball)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
