{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial - Sampling sparse logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Shidi Zhao (zhao5@fb.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this tutorial is to showcase how to write a sparse logistic regression model in Bean Machine and present some inference methods that Bean Machine provides to sample this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a very commonly used statistical method that allows us to predict a binary output from a set of independent variables. Suppose we have some prior knowledge about the data generated from the logistic regression model, we can sample the logistic regression model from the prior. The sparse logistic regression is a type of logistic regression model, it embeds feature selection in the classification by adding overall and pre-dimension scale factors, and has many applications in high-dimensional data, such as classifying credit score. So here, to sample the sparse logistic regression in Bean Machine, we first implement the sparse logistic regression model in Bean Machine and then try to sample it with various inference methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse logistic regression is a hierarchical logistic regression with a sparse prior $\\tau$. We consider the model as following:\n",
    "\n",
    "   $$\n",
    "\\begin{array}{lcl}\n",
    "\\tau {\\sim} Gamma(\\alpha = 0.5, \\beta = 0.5) \\\\\n",
    "\\lambda_d{\\sim} Gamma(\\alpha = 0.5, \\beta = 0.5) \\\\\n",
    "\\beta_d{\\sim} Normal(0,1) \\\\\n",
    "y_n{\\sim}Bernoulli(\\sigma{X}^T(\\tau\\beta \\circ \\lambda)) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Here $\\tau$ is the global shrinkage, $\\lambda$ is local shrinkage,$\\beta \\circ \\lambda$ denotes the elementwise product of $\\beta$ and $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please import the following code packages for the rest of the code in the tutorial to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import beanmachine.ppl as bm\n",
    "from torch.distributions import *\n",
    "import torch.nn as nn\n",
    "from beanmachine.ppl.diagnostics.common_statistics import effective_sample_size, split_r_hat,r_hat\n",
    "from beanmachine.ppl.inference.abstract_infer import (\n",
    "    VerboseLevel,\n",
    ")\n",
    "from torch import tensor,manual_seed, arange, float32, zeros, ones, randn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the prior knowledge about the model, we can generate some data (x,y) use a pre-defined sparse logistic regression model with generated $\\tau$-value, $\\lambda$-value, and $\\beta$-value. Then we split the data into training data(50%) and testing data(50%). For the training data, we are going to run inference on it, and for the testing data, we are going to compute the predictive log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manual_seed(38)\n",
    "\n",
    "D=3 #number of predictors\n",
    "N=100 #number of observations\n",
    "\n",
    "tau_value = Gamma(tensor(0.5),tensor(0.5)).sample()\n",
    "lambda_value = Gamma(0.5,0.5).sample(sample_shape=(D,1))\n",
    "beta_value = Normal(0,1).sample(sample_shape=(D,1))\n",
    "X = Normal(0,10).sample(sample_shape=(N,D)) \n",
    "mu = X.mm(torch.mul(tau_value*beta_value,lambda_value))\n",
    "Y= Bernoulli(logits=mu).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size=test_size= int(N/2)\n",
    "\n",
    "TRAIN_DATA_X = X[:train_size]\n",
    "TEST_DATA_X = X[test_size:]\n",
    "TRAIN_DATA_Y = Y[:train_size]\n",
    "TEST_DATA_Y = Y[test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement sparse logistic regression model in Bean Machine, we have random variable $\\tau$(), $\\lambda$(), $\\beta$() and y(). Here, we sample the random variables using MCMC, the observation here is the training data. Then we compute the predictive log-likelihood using test data. The predictive log-likelihood has an important role in statistical model comparison, the highest predictive log-likelihood will have the highest posterior probability, thus it can measure how the model fits overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sparse(object):\n",
    "    def __init__(self,num_predictors,train_x,test_x,test_y):\n",
    "        self.D = num_predictors\n",
    "        self.TRAIN_DATA_X = train_x\n",
    "        self.TEST_DATA_X=test_x\n",
    "        self.TEST_DATA_Y=test_y\n",
    "        \n",
    "    @bm.random_variable\n",
    "    def tau(self):\n",
    "        return Gamma(tensor(0.5), tensor(0.5))\n",
    "\n",
    "    @bm.random_variable\n",
    "    def lambda_(self):\n",
    "        return Gamma(tensor([[0.5]] * (self.D)), tensor([[0.5]] * (self.D)))\n",
    "\n",
    "    @bm.random_variable\n",
    "    def beta(self):\n",
    "        return Normal(zeros((self.D, 1)), ones((self.D, 1)))\n",
    "\n",
    "    @bm.random_variable\n",
    "    def y(self):\n",
    "        y_=self.TRAIN_DATA_X.mm(torch.mul(self.tau()*self.beta(),self.lambda_()))\n",
    "        return Bernoulli(logits=y_)\n",
    "\n",
    "    @bm.functional\n",
    "    def log_prob_test(self):\n",
    "        y = self.TEST_DATA_X.mm(torch.mul(self.tau()*self.beta(),self.lambda_()))\n",
    "        s =(Bernoulli(logits=y)).log_prob(self.TEST_DATA_Y).sum()\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will go through the performance of different inference methods on this model. We will investigate different inference algorithms, single-site Hamiltonian Monte Carlo (HMC), single-site MetropolisHastings, and single-site Newtonian Monte Carlo (NMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-site NMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = Sparse(D,TRAIN_DATA_X,TEST_DATA_X,TEST_DATA_Y)\n",
    "dict_y = {s.y(): TRAIN_DATA_Y}\n",
    "nw = bm.SingleSiteNewtonianMonteCarlo()\n",
    "samples_nw = nw.infer([s.log_prob_test(),s.tau(),s.lambda_(),s.beta()], dict_y , 10, 3,verbose=VerboseLevel.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_nw = tensor(samples_nw[s.log_prob_test()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AnalysisÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we compare the mean value of tao, lambda and beat with the generated $\\tau$-value, $\\lambda$-value, and $\\beta$-value, and compute the effective sample size and r hat of the samples as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analysis(label,samples, model_tao,model_lambda,model_beta,D):\n",
    "    \n",
    "    Tau = samples[model_tao].detach()\n",
    "    Lambda = samples[model_lambda].detach()\n",
    "    Beta=samples[model_beta].detach()\n",
    "    \n",
    "    print(\"for \"+label+\":\")\n",
    "    print(\"Predicted Tao mean:\", round(samples[model_tao].mean().item(), 3), \"vs Tau that data was generated with:\", round(tau_value.mean().item(), 3))\n",
    "    print(\"Predicted Lambda mean:\", round(samples[model_lambda].mean().item(), 3), \"vs Lambda that data was generated with:\", round(lambda_value.mean().item(), 3))\n",
    "    print(\"Predicted Tao mean:\", round(samples[model_beta].mean().item(), 3), \"vs Beta that data was generated with:\", round(beta_value.mean().item(), 3))\n",
    "    \n",
    "    print(\"effective sample size\", effective_sample_size(Tau),\", r hat\", split_r_hat(Tau))\n",
    "    print(\"effective sample size\", effective_sample_size(Lambda).view(1,D),\", r hat\", split_r_hat(Lambda).view(1,D))\n",
    "    print(\"effective sample size\", effective_sample_size(Beta).view(1,D),\", r hat\", split_r_hat(Beta).view(1,D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Single-site NMC:\n",
      "Predicted Tao mean: 3.864 vs Tau that data was generated with: 1.136\n",
      "Predicted Lambda mean: 0.935 vs Lambda that data was generated with: 0.15\n",
      "Predicted Tao mean: -0.073 vs Beta that data was generated with: -1.044\n",
      "effective sample size tensor(3.6529) , r hat tensor(1.7423)\n",
      "effective sample size tensor([[1.8104, 1.8104, 1.8104]]) , r hat tensor([[2.7203, 2.7203, 2.7203]])\n",
      "effective sample size tensor([[2.5923, 4.0948, 3.7746]]) , r hat tensor([[1.5838, 1.5343, 1.3231]])\n"
     ]
    }
   ],
   "source": [
    "analysis(\"Single-site NMC\",samples_nw,s.tau(),s.lambda_(),s.beta(),D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis, we can see the lambda would get stuck with half-space proposer in NMC. Since it is in half-space, so it initializes the value with 1. We can see from the mean value of $\\lambda$, it does not move. And we try with the current real space proposer, the acceptance is 5% for 100 samples. We would continue working on this model with the latest NMC inference method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-site MetropolisHastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = Sparse(D,TRAIN_DATA_X,TEST_DATA_X,TEST_DATA_Y)\n",
    "mh = bm.SingleSiteAncestralMetropolisHastings()\n",
    "samples_mh = mh.infer([s.log_prob_test(),s.tau(),s.lambda_(),s.beta()], dict_y, 10, 3,verbose=VerboseLevel.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_mh = tensor(samples_mh[s.log_prob_test()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Single-site MH:\n",
      "Predicted Tao mean: 1.336 vs Tau that data was generated with: 1.136\n",
      "Predicted Lambda mean: 0.863 vs Lambda that data was generated with: 0.15\n",
      "Predicted Tao mean: 0.015 vs Beta that data was generated with: -1.044\n",
      "effective sample size tensor(134.0233) , r hat tensor(0.9615)\n",
      "effective sample size tensor([[28.8424, 42.0718, 17.6982]]) , r hat tensor([[0.9506, 0.9850, 0.9781]])\n",
      "effective sample size tensor([[10.3614, 43.0382, 25.2414]]) , r hat tensor([[1.1139, 0.9914, 1.0146]])\n"
     ]
    }
   ],
   "source": [
    "analysis(\"Single-site MH\",samples_mh,s.tau(),s.lambda_(),s.beta(),D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-site HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = Sparse(D,TRAIN_DATA_X,TEST_DATA_X,TEST_DATA_Y)\n",
    "step_size = 0.5\n",
    "num_steps=1\n",
    "hmc = bm.SingleSiteHamiltonianMonteCarlo(step_size, num_steps)\n",
    "samples_hmc = mh.infer([s.log_prob_test(),s.tau(),s.lambda_(),s.beta()], dict_y , 10, 3,verbose=VerboseLevel.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Single-site HMC:\n",
      "Predicted Tao mean: 1.0 vs Tau that data was generated with: 1.136\n",
      "Predicted Lambda mean: 1.0 vs Lambda that data was generated with: 0.15\n",
      "Predicted Tao mean: 0.0 vs Beta that data was generated with: -1.044\n",
      "effective sample size tensor(nan) , r hat tensor(nan)\n",
      "effective sample size tensor([[nan, nan, nan]]) , r hat tensor([[nan, nan, nan]])\n",
      "effective sample size tensor([[nan, nan, nan]]) , r hat tensor([[nan, nan, nan]])\n"
     ]
    }
   ],
   "source": [
    "analysis(\"Single-site HMC\",samples_hmc,s.tau(),s.lambda_(),s.beta(),D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_hmc = tensor(samples_hmc[s.log_prob_test()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fda29585310>]"
      ]
     },
     "execution_count": 1130,
     "metadata": {
      "bento_obj_id": "140575013208224"
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "bento_obj_id": "140575027569296",
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_nw=post_nw.cumsum(dim=0) / arange(1, len(post_mh[0])+1)\n",
    "p_mh=post_mh.cumsum(dim=0)/ arange(1, len(post_mh[0])+1)\n",
    "p_hmc=post_hmc.cumsum(dim=0) / arange(1, len(post_hmc[0])+1)\n",
    "\n",
    "plt.plot(p_nw[-1],color=\"purple\",linewidth=5)\n",
    "plt.plot(p_mh[-1],color=\"orange\",linewidth=5)\n",
    "plt.plot(p_hmc[-1],color=\"blue\",linewidth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German-numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider our sparse logistic regression model with German credit dataset, you can download the data from: https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric. \n",
    "We use the numeric variant of the german credit dataset, with the covariates standardized to range between -1 and 1. With the addition of a constant factor, this yields 25 covariates (the data preprocess is the same as [NeuTra](https://arxiv.org/pdf/1903.03704.pdf) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"german.data-numeric\")\n",
    "x = data[:, :-1]\n",
    "y = (data[:, -1] - 1)\n",
    "x_min = np.min(x, 0, keepdims=True)\n",
    "x_max = np.max(x, 0, keepdims=True)\n",
    "x /= (x_max - x_min)\n",
    "x = 2.0 * x - 1.0\n",
    "x = np.concatenate([x, np.ones([x.shape[0], 1])], -1)\n",
    "x =[torch.from_numpy(x[i]) for i in range(1000)]\n",
    "y = torch.from_numpy(y).view(len(x),1)\n",
    "D,N=len(x[0]),len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to use all the data to train the model, we do not have test data as the previous case. here in the input, test data is the same as training data, which is the whole data set. And we use log_prob_test() to compute the predictive log-likelihood of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_X = torch.stack(x).float()\n",
    "TEST_DATA_X = torch.stack(x).float()\n",
    "TRAIN_DATA_Y = y\n",
    "TEST_DATA_Y=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = Sparse(D,TRAIN_DATA_X,TEST_DATA_X,TEST_DATA_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_y = {s.y(): TRAIN_DATA_Y}\n",
    "\n",
    "s = Sparse(D,TRAIN_DATA_X,TEST_DATA_X,TEST_DATA_Y)\n",
    "nw = bm.SingleSiteNewtonianMonteCarlo()\n",
    "samples_nw = nw.infer([s.tau(),s.lambda_(),s.beta()], dict_y , 10, 3,verbose=VerboseLevel.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Single-site NMC:\n",
      "Predicted Tao mean: 1.027 vs Tau that data was generated with: 1.136\n",
      "Predicted Lambda mean: 1.0 vs Lambda that data was generated with: 0.15\n",
      "Predicted Tao mean: -0.001 vs Beta that data was generated with: -1.044\n",
      "effective sample size tensor(34.3803) , r hat tensor(0.9936)\n",
      "effective sample size tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan]]) , r hat tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan]])\n",
      "effective sample size tensor([[  16.1713,   18.6361,    7.0798,   21.5570,   21.0521, 2130.0254,\n",
      "           12.0979,    9.0913,   46.4759,   37.1142,   19.3713,   32.6580,\n",
      "           26.6086,   26.8423,   22.4751,   19.2516,   26.7237,   18.2936,\n",
      "           20.5685,   14.2885,    5.5679,   20.7948,    9.6529,   15.3659,\n",
      "           21.5948]]) , r hat tensor([[1.1251, 1.1507, 1.2530, 0.9701, 1.0502, 0.9238, 1.1358, 1.0813, 1.0412,\n",
      "         0.9577, 0.9801, 0.9637, 0.9412, 1.0397, 1.1303, 1.0751, 1.0604, 0.9994,\n",
      "         1.0067, 1.0922, 1.1823, 1.0819, 1.1001, 0.9800, 1.0330]])\n"
     ]
    }
   ],
   "source": [
    "analysis(\"Single-site NMC\",samples_nw,s.tau(),s.lambda_(),s.beta(),D)"
   ]
  }
 ],
 "metadata": {
  "anp_cloned_from": {
   "notebook_id": "1317952768402874",
   "revision_id": "294048698638911"
  },
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "1317952768402874"
  },
  "disseminate_notebook_info": {
   "bento_version": "20200601-000343",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "deps": [
     "//beanmachine:bento_deps"
    ],
    "external_deps": []
   },
   "no_uii": true,
   "notebook_number": "275391",
   "others_can_edit": false,
   "reviewers": "",
   "revision_id": "271583090655679",
   "tags": "",
   "tasks": "",
   "title": "Implement sparse logistic regression "
  },
  "kernelspec": {
   "display_name": "beanmachine",
   "language": "python",
   "name": "bento_kernel_beanmachine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
