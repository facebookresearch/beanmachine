{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport beanmachine.ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a72ea39762407b9efca9fc500403b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(85.0159)\n",
      "{RVIdentifier(wrapper=<function phi at 0x7f90262811f0>, arguments=()): tensor([0., 0.], requires_grad=True)}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspace/beanmachine/tutorials/Variational_Inference.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=27'>28</a>\u001b[0m     params \u001b[39m=\u001b[39m phi()\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dist\u001b[39m.\u001b[39mNormal(params[\u001b[39m0\u001b[39m], params[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mexp())\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=30'>31</a>\u001b[0m world \u001b[39m=\u001b[39m bm\u001b[39m.\u001b[39;49mVariationalInfer()\u001b[39m.\u001b[39;49minfer(\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=31'>32</a>\u001b[0m     queries_to_guides\u001b[39m=\u001b[39;49m{model\u001b[39m.\u001b[39;49mmu(): q_mu()},\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=32'>33</a>\u001b[0m     observations\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=33'>34</a>\u001b[0m         model\u001b[39m.\u001b[39;49mx(\u001b[39m1\u001b[39;49m): torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m9.0\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=34'>35</a>\u001b[0m         model\u001b[39m.\u001b[39;49mx(\u001b[39m2\u001b[39;49m): torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m10.0\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=35'>36</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=36'>37</a>\u001b[0m     num_steps\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=37'>38</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m params: optim\u001b[39m.\u001b[39;49mAdam(params, lr\u001b[39m=\u001b[39;49m\u001b[39m1e-1\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B633a5c55736572735c4665796e6d616e204c69616e675c4f6e6544726976655c446f63756d656e74735c32312d3232/workspace/beanmachine/tutorials/Variational_Inference.ipynb#ch0000002vscode-remote?line=38'>39</a>\u001b[0m )\n",
      "File \u001b[0;32m/workspace/beanmachine/src/beanmachine/ppl/inference/variational/variational_infer.py:78\u001b[0m, in \u001b[0;36mVariationalInfer.infer\u001b[0;34m(self, queries_to_guides, observations, num_steps, optimizer, num_samples, num_importance_samples, discrepancy_fn)\u001b[0m\n\u001b[1;32m     <a href='file:///workspace/beanmachine/src/beanmachine/ppl/inference/variational/variational_infer.py?line=75'>76</a>\u001b[0m     \u001b[39mprint\u001b[39m(params)\n\u001b[1;32m     <a href='file:///workspace/beanmachine/src/beanmachine/ppl/inference/variational/variational_infer.py?line=76'>77</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39misnan(loss):\n\u001b[0;32m---> <a href='file:///workspace/beanmachine/src/beanmachine/ppl/inference/variational/variational_infer.py?line=77'>78</a>\u001b[0m         loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='file:///workspace/beanmachine/src/beanmachine/ppl/inference/variational/variational_infer.py?line=78'>79</a>\u001b[0m         opt\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='file:///workspace/beanmachine/src/beanmachine/ppl/inference/variational/variational_infer.py?line=80'>81</a>\u001b[0m \u001b[39mreturn\u001b[39;00m world\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///root/micromamba/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import beanmachine.ppl as bm\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import torch.optim as optim\n",
    "\n",
    "class NormalNormal:\n",
    "    def __init__(self):\n",
    "        self.device = 'cpu'\n",
    "\n",
    "    @bm.random_variable\n",
    "    def mu(self):\n",
    "        return dist.Normal(\n",
    "            torch.zeros(1).to(self.device), 10 * torch.ones(1).to(self.device)\n",
    "        )\n",
    "\n",
    "    @bm.random_variable\n",
    "    def x(self, i):\n",
    "        return dist.Normal(self.mu(), torch.ones(1).to(self.device))\n",
    "\n",
    "model = NormalNormal()\n",
    "\n",
    "@bm.param\n",
    "def phi():\n",
    "    return torch.zeros(2)  # mean, log std\n",
    "\n",
    "@bm.random_variable\n",
    "def q_mu():\n",
    "    params = phi()\n",
    "    print(params)\n",
    "    return dist.Normal(params[0], params[1].exp())\n",
    "\n",
    "world = bm.VariationalInfer().infer(\n",
    "    queries_to_guides={model.mu(): q_mu()},\n",
    "    observations={\n",
    "        model.x(1): torch.tensor(9.0),\n",
    "        model.x(2): torch.tensor(10.0),\n",
    "    },\n",
    "    num_steps=100,\n",
    "    optimizer=lambda params: optim.Adam(params, lr=1e-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: -1.4006761312484741, scale: 25045.5)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world._run_node(q_mu())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d13082b4bd245bb7b08aea3b25cb3b8185404358d859b3f501f7ea456008ea8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
